{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416b15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "NUM_CLUSTERS = 10  # Reduced from 25 to create more balanced clusters\n",
    "MAX_GAMES = 200000\n",
    "\n",
    "# Set to True to force retraining even if saved models exist\n",
    "FORCE_RETRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248f21dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 145767 games (limited to 200000)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "index = 0\n",
    "\n",
    "all_games = []\n",
    "for file_path in glob.glob('data/games_slim/*.json'):\n",
    "    if len(all_games) >= MAX_GAMES:\n",
    "        break\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    index += 1\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Loaded {index} files...\", end='\\r')\n",
    "\n",
    "    all_games.append(data)\n",
    "\n",
    "print(f\"Loaded {len(all_games)} games (limited to {MAX_GAMES})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16745336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deduplication: 123567 unique games (from 145767 total)\n"
     ]
    }
   ],
   "source": [
    "unique_games = {}\n",
    "\n",
    "for game in all_games:\n",
    "    title = (game.get(\"title\") or \"\").strip().lower()\n",
    "    devs = tuple(sorted((game.get(\"developer\") or [])))\n",
    "    pubs = tuple(sorted((game.get(\"publisher\") or [])))\n",
    "    key = (title, devs, pubs)\n",
    "\n",
    "    current_best = unique_games.get(key)\n",
    "    if current_best is None:\n",
    "        unique_games[key] = game\n",
    "    else:\n",
    "        # Keep the one with the highest review_count\n",
    "        if (game.get(\"review_count\") or 0) > (current_best.get(\"review_count\") or 0):\n",
    "            unique_games[key] = game\n",
    "\n",
    "deduped_games = list(unique_games.values())\n",
    "\n",
    "print(f\"After deduplication: {len(deduped_games)} unique games (from {len(all_games)} total)\")\n",
    "all_games = deduped_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356fa656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted prices for 89960 games\n"
     ]
    }
   ],
   "source": [
    "prices = []\n",
    "for game in all_games:\n",
    "    price_str = game.get('price', '')\n",
    "    if price_str:\n",
    "        if 'free' in price_str.lower():\n",
    "            prices.append(0.0)\n",
    "        else:\n",
    "            price_clean = price_str.replace('zł', '').replace(',', '.').strip()\n",
    "            try:\n",
    "                price = float(price_clean)\n",
    "                prices.append(price)\n",
    "            except ValueError:\n",
    "                prices.append(None)\n",
    "    else:\n",
    "        prices.append(None)\n",
    "\n",
    "print(f\"Extracted prices for {len([p for p in prices if p is not None])} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82f70f",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbcb5fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 123567 text documents\n",
      "Vectorized to shape: (123567, 1000)\n",
      "Clustering completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Counter-Strike 2"
          ],
          [
           "Dota 2"
          ],
          [
           "Tom Clancy's Rainbow Six® Siege X"
          ],
          [
           "Team Fortress 2"
          ],
          [
           "HELLDIVERS™ 2"
          ],
          [
           "Grand Theft Auto V Legacy"
          ],
          [
           "Terraria"
          ],
          [
           "Garry's Mod"
          ],
          [
           "Rust"
          ],
          [
           "PUBG: BATTLEGROUNDS"
          ],
          [
           "Apex Legends™"
          ],
          [
           "Baldur's Gate 3"
          ],
          [
           "ELDEN RING"
          ],
          [
           "Destiny 2"
          ],
          [
           "Stardew Valley"
          ],
          [
           "Among Us"
          ],
          [
           "Cyberpunk 2077"
          ],
          [
           "Phasmophobia"
          ],
          [
           "War Thunder"
          ],
          [
           "Warframe"
          ],
          [
           "Lethal Company"
          ],
          [
           "Red Dead Redemption 2"
          ],
          [
           "ARK: Survival Evolved"
          ],
          [
           "Valheim"
          ],
          [
           "Marvel Rivals"
          ],
          [
           "Dead by Daylight"
          ],
          [
           "The Witcher 3: Wild Hunt"
          ],
          [
           "Call of Duty®"
          ],
          [
           "Rocket League®"
          ],
          [
           "Unturned"
          ],
          [
           "Left 4 Dead 2"
          ],
          [
           "Bloons TD 6"
          ],
          [
           "Wallpaper Engine"
          ],
          [
           "Geometry Dash"
          ],
          [
           "tModLoader"
          ],
          [
           "BeamNG.drive"
          ],
          [
           "PAYDAY 2"
          ],
          [
           "The Forest"
          ],
          [
           "No Man's Sky"
          ],
          [
           "DayZ"
          ],
          [
           "Fallout 4"
          ],
          [
           "Brawlhalla"
          ],
          [
           "Fall Guys"
          ],
          [
           "Subnautica"
          ],
          [
           "VRChat"
          ],
          [
           "People Playground"
          ],
          [
           "Portal 2"
          ],
          [
           "Deep Rock Galactic"
          ],
          [
           "Schedule I"
          ],
          [
           "Hollow Knight"
          ],
          [
           "Halo: The Master Chief Collection"
          ],
          [
           "Undertale"
          ],
          [
           "Risk of Rain 2"
          ],
          [
           "Palworld"
          ],
          [
           "New World: Aeternum"
          ],
          [
           "Sea of Thieves: 2025 Edition"
          ],
          [
           "THE FINALS"
          ],
          [
           "Path of Exile"
          ],
          [
           "Halo Infinite"
          ],
          [
           "Ready or Not"
          ],
          [
           "Project Zomboid"
          ],
          [
           "Hades"
          ],
          [
           "Hogwarts Legacy"
          ],
          [
           "The Binding of Isaac: Rebirth"
          ],
          [
           "Euro Truck Simulator 2"
          ],
          [
           "Overwatch® 2"
          ],
          [
           "Paladins®"
          ],
          [
           "Raft"
          ],
          [
           "Vampire Survivors"
          ],
          [
           "Doki Doki Literature Club!"
          ],
          [
           "Satisfactory"
          ],
          [
           "ULTRAKILL"
          ],
          [
           "Borderlands 2"
          ],
          [
           "7 Days to Die"
          ],
          [
           "The Elder Scrolls V: Skyrim Special Edition"
          ],
          [
           "DOOM Eternal"
          ],
          [
           "Hearts of Iron IV"
          ],
          [
           "Monster Hunter: World"
          ],
          [
           "RimWorld"
          ],
          [
           "Call of Duty®: Black Ops III"
          ],
          [
           "Factorio"
          ],
          [
           "Arma 3"
          ],
          [
           "Battlefield™ 2042"
          ],
          [
           "Sons Of The Forest"
          ],
          [
           "Lost Ark"
          ],
          [
           "Sid Meier’s Civilization® VI"
          ],
          [
           "DARK SOULS™ III"
          ],
          [
           "Hollow Knight: Silksong"
          ],
          [
           "The Elder Scrolls V: Skyrim"
          ],
          [
           "Muck"
          ],
          [
           "Cities: Skylines"
          ],
          [
           "The Sims™ 4"
          ],
          [
           "Dying Light"
          ],
          [
           "R.E.P.O."
          ],
          [
           "Mount & Blade II: Bannerlord"
          ],
          [
           "Hunt: Showdown 1896"
          ],
          [
           "Balatro"
          ],
          [
           "SCP: Secret Laboratory"
          ],
          [
           "Titanfall® 2"
          ],
          [
           "Splitgate"
          ],
          [
           "American Truck Simulator"
          ],
          [
           "Crab Game"
          ],
          [
           "Forza Horizon 5"
          ],
          [
           "Half-Life 2"
          ],
          [
           "Path of Exile 2"
          ],
          [
           "Starfield"
          ],
          [
           "Sekiro™: Shadows Die Twice - GOTY Edition"
          ],
          [
           "DOOM"
          ],
          [
           "Warhammer 40,000: Space Marine 2"
          ],
          [
           "Squad"
          ],
          [
           "Divinity: Original Sin 2 - Definitive Edition"
          ],
          [
           "Don't Starve Together"
          ],
          [
           "STAR WARS Jedi: Fallen Order™"
          ],
          [
           "Totally Accurate Battle Simulator"
          ],
          [
           "BattleBit Remastered"
          ],
          [
           "Portal"
          ],
          [
           "Sid Meier's Civilization® V"
          ],
          [
           "MultiVersus"
          ],
          [
           "Life is Strange - Episode 1"
          ],
          [
           "Stray"
          ],
          [
           "Once Human"
          ],
          [
           "Monster Hunter Wilds"
          ],
          [
           "Kerbal Space Program"
          ],
          [
           "Stellaris"
          ],
          [
           "Inscryption"
          ],
          [
           "The Elder Scrolls® Online"
          ],
          [
           "Battlefield™ 6"
          ],
          [
           "Slay the Spire"
          ],
          [
           "SMITE®"
          ],
          [
           "Teardown"
          ],
          [
           "Warhammer 40,000: Darktide"
          ],
          [
           "Clair Obscur: Expedition 33"
          ],
          [
           "Far Cry® 5"
          ],
          [
           "Space Engineers"
          ],
          [
           "Black Mesa"
          ],
          [
           "Black Myth: Wukong"
          ],
          [
           "Dying Light 2 Stay Human: Reloaded Edition"
          ],
          [
           "Grand Theft Auto IV: The Complete Edition"
          ],
          [
           "Aimlabs"
          ],
          [
           "Slime Rancher"
          ],
          [
           "ELDEN RING NIGHTREIGN"
          ],
          [
           "Cuphead"
          ],
          [
           "Hell Let Loose"
          ],
          [
           "Delta Force"
          ],
          [
           "MORDHAU"
          ],
          [
           "Half-Life: Alyx"
          ],
          [
           "Borderlands 3"
          ],
          [
           "FINAL FANTASY XIV Online"
          ],
          [
           "Insurgency: Sandstorm"
          ],
          [
           "Kingdom Come: Deliverance"
          ],
          [
           "Robocraft"
          ],
          [
           "Z1 Battle Royale"
          ],
          [
           "theHunter: Call of the Wild™"
          ],
          [
           "Age of Empires II: Definitive Edition"
          ],
          [
           "Last Epoch"
          ],
          [
           "Forza Horizon 4"
          ],
          [
           "Totally Accurate Battlegrounds"
          ],
          [
           "Assassin's Creed® Odyssey"
          ],
          [
           "Heroes & Generals"
          ],
          [
           "God of War"
          ],
          [
           "Celeste"
          ],
          [
           "Rec Room"
          ],
          [
           "Assetto Corsa"
          ],
          [
           "Darkest Dungeon®"
          ],
          [
           "Half-Life"
          ],
          [
           "Mount & Blade: Warband"
          ],
          [
           "Firewatch"
          ],
          [
           "FOR HONOR™"
          ],
          [
           "Helltaker"
          ],
          [
           "Disco Elysium - The Final Cut"
          ],
          [
           "Cult of the Lamb"
          ],
          [
           "Beat Saber"
          ],
          [
           "Resident Evil 4"
          ],
          [
           "Stick Fight: The Game"
          ],
          [
           "OMORI"
          ],
          [
           "V Rising"
          ],
          [
           "Subnautica: Below Zero"
          ],
          [
           "DELTARUNE"
          ],
          [
           "Starbound"
          ],
          [
           "The Isle"
          ],
          [
           "ASTRONEER"
          ],
          [
           "Horizon Zero Dawn™ Complete Edition"
          ],
          [
           "Elite Dangerous"
          ],
          [
           "Total War: WARHAMMER II"
          ],
          [
           "Total War: WARHAMMER III"
          ],
          [
           "STAR WARS™: The Old Republic™"
          ],
          [
           "The First Descendant"
          ],
          [
           "Cookie Clicker"
          ],
          [
           "WEBFISHING"
          ],
          [
           "Tomb Raider"
          ],
          [
           "Marvel’s Spider-Man Remastered"
          ],
          [
           "Hades II"
          ],
          [
           "Resident Evil 2"
          ],
          [
           "Crusader Kings II"
          ],
          [
           "Blade and Sorcery"
          ],
          [
           "NieR:Automata™"
          ],
          [
           "Need for Speed™ Heat"
          ],
          [
           "PlanetSide 2"
          ],
          [
           "World of Warships"
          ],
          [
           "Europa Universalis IV"
          ],
          [
           "DARK SOULS™: Prepare To Die™ Edition"
          ],
          [
           "Oxygen Not Included"
          ],
          [
           "BioShock Infinite"
          ],
          [
           "Outer Wilds"
          ],
          [
           "ARK: Survival Ascended"
          ],
          [
           "STAR WARS™ Battlefront™ II"
          ],
          [
           "Batman™: Arkham Knight"
          ],
          [
           "Yu-Gi-Oh! Master Duel"
          ],
          [
           "Crusader Kings III"
          ],
          [
           "FTL: Faster Than Light"
          ],
          [
           "Scrap Mechanic"
          ],
          [
           "Kingdom Come: Deliverance II"
          ],
          [
           "DAVE THE DIVER"
          ],
          [
           "Poppy Playtime"
          ],
          [
           "STAR WARS Jedi: Survivor™"
          ],
          [
           "Noita"
          ],
          [
           "Kenshi"
          ],
          [
           "House Flipper"
          ],
          [
           "Dark and Darker"
          ],
          [
           "DARK SOULS™: REMASTERED"
          ],
          [
           "Persona 4 Golden"
          ],
          [
           "Just Cause™ 3"
          ],
          [
           "Ravenfield"
          ],
          [
           "Pizza Tower"
          ],
          [
           "Counter-Strike: Source"
          ],
          [
           "XCOM® 2"
          ],
          [
           "It Takes Two"
          ],
          [
           "It Takes Two Friend's Pass"
          ],
          [
           "Castle Crashers®"
          ],
          [
           "The Elder Scrolls IV: Oblivion Remastered"
          ],
          [
           "Dead Cells"
          ],
          [
           "Dragon's Dogma 2"
          ],
          [
           "Trove"
          ],
          [
           "Warhammer: Vermintide 2"
          ],
          [
           "Microsoft Flight Simulator (2020) 40th Anniversary Edition"
          ],
          [
           "Killing Floor 2"
          ],
          [
           "Battlefield™ 1"
          ],
          [
           "Dune: Awakening"
          ],
          [
           "Detroit: Become Human"
          ],
          [
           "Fallout 76"
          ],
          [
           "Resident Evil Village"
          ],
          [
           "METAL GEAR SOLID V: THE PHANTOM PAIN"
          ],
          [
           "POSTAL 2"
          ],
          [
           "Planet Zoo"
          ],
          [
           "Far Cry 3"
          ],
          [
           "Getting Over It with Bennett Foddy"
          ],
          [
           "FIFA 22"
          ],
          [
           "Gray Zone Warfare"
          ],
          [
           "Hotline Miami"
          ],
          [
           "Plants vs. Zombies GOTY Edition"
          ],
          [
           "Enshrouded"
          ],
          [
           "Grounded"
          ],
          [
           "CarX Drift Racing Online"
          ],
          [
           "S.T.A.L.K.E.R. 2: Heart of Chornobyl"
          ],
          [
           "ARMORED CORE™ VI FIRES OF RUBICON™"
          ],
          [
           "Enter the Gungeon"
          ],
          [
           "Stormworks: Build and Rescue"
          ],
          [
           "METAL GEAR RISING: REVENGEANCE"
          ],
          [
           "The Long Dark"
          ],
          [
           "Gorilla Tag"
          ],
          [
           "Papers, Please"
          ],
          [
           "AdVenture Capitalist"
          ],
          [
           "Just Survive"
          ],
          [
           "Grim Dawn"
          ],
          [
           "Mass Effect™ Legendary Edition"
          ],
          [
           "Frostpunk"
          ],
          [
           "The Henry Stickmin Collection"
          ],
          [
           "Conan Exiles"
          ],
          [
           "Yakuza 0"
          ],
          [
           "PowerWash Simulator"
          ],
          [
           "Blender"
          ],
          [
           "SCUM"
          ],
          [
           "Age of Empires II (Retired)"
          ],
          [
           "SPORE™"
          ],
          [
           "Borderlands 4"
          ],
          [
           "Devil May Cry 5"
          ],
          [
           "Five Nights at Freddy's: Security Breach"
          ],
          [
           "EA SPORTS™ FIFA 23"
          ],
          [
           "Insurgency"
          ],
          [
           "Gunfire Reborn"
          ],
          [
           "Tom Clancy's Ghost Recon® Wildlands"
          ],
          [
           "Cry of Fear"
          ],
          [
           "Black Desert"
          ],
          [
           "Manor Lords"
          ],
          [
           "STAR WARS™ Battlefront II (Classic, 2005)"
          ],
          [
           "Dirty Bomb®"
          ],
          [
           "Assassin's Creed® Origins"
          ],
          [
           "Golf With Your Friends"
          ],
          [
           "Middle-earth™: Shadow of War™"
          ],
          [
           "Days Gone"
          ],
          [
           "Limbus Company"
          ],
          [
           "Grand Theft Auto V Enhanced"
          ],
          [
           "Counter-Strike"
          ],
          [
           "Battlefield™ V"
          ],
          [
           "Prison Architect"
          ],
          [
           "Dota Underlords"
          ],
          [
           "My Summer Car"
          ],
          [
           "Don't Starve"
          ],
          [
           "Metro Exodus"
          ],
          [
           "Call of Duty: World at War"
          ],
          [
           "MONSTER HUNTER RISE"
          ],
          [
           "Realm of the Mad God Exalt"
          ],
          [
           "HITMAN™ 2"
          ],
          [
           "DARK SOULS™ II: Scholar of the First Sin"
          ],
          [
           "EA SPORTS FC™ 24"
          ],
          [
           "Middle-earth™: Shadow of Mordor™"
          ],
          [
           "Escape the Backrooms"
          ],
          [
           "THRONE AND LIBERTY"
          ],
          [
           "Ghost of Tsushima DIRECTOR'S CUT"
          ],
          [
           "The Elder Scrolls IV: Oblivion® Game of the Year Edition (2009)"
          ],
          [
           "Stumble Guys"
          ],
          [
           "GUILTY GEAR -STRIVE-"
          ],
          [
           "Five Nights at Freddy's"
          ],
          [
           "Pavlov"
          ],
          [
           "The Planet Crafter"
          ],
          [
           "Total War: ROME II - Emperor Edition"
          ],
          [
           "Planet Coaster"
          ],
          [
           "Content Warning"
          ],
          [
           "PAYDAY 3"
          ],
          [
           "OUTRIDERS"
          ],
          [
           "Fallout Shelter"
          ],
          [
           "TEKKEN 7"
          ],
          [
           "Buckshot Roulette"
          ],
          [
           "No More Room in Hell"
          ],
          [
           "Ultimate Custom Night"
          ],
          [
           "Supermarket Simulator"
          ],
          [
           "Deceit"
          ],
          [
           "Cities: Skylines II"
          ],
          [
           "Goat Simulator"
          ],
          [
           "Human Fall Flat"
          ],
          [
           "Ori and the Will of the Wisps"
          ],
          [
           "Red Dead Online"
          ],
          [
           "Tabletop Simulator"
          ],
          [
           "OneShot"
          ],
          [
           "Ori and the Blind Forest: Definitive Edition"
          ],
          [
           "South Park™: The Stick of Truth™"
          ],
          [
           "Warface: Clutch"
          ],
          [
           "The Outlast Trials"
          ],
          [
           "TCG Card Shop Simulator"
          ],
          [
           "BONEWORKS"
          ],
          [
           "My Singing Monsters"
          ],
          [
           "Ring of Elysium"
          ],
          [
           "Persona 5 Royal"
          ],
          [
           "Fallout 3: Game of the Year Edition"
          ],
          [
           "Rise of the Tomb Raider™"
          ],
          [
           "A Hat in Time"
          ],
          [
           "Source Filmmaker"
          ],
          [
           "Clicker Heroes"
          ],
          [
           "DREDGE"
          ],
          [
           "The Stanley Parable"
          ],
          [
           "Hellblade: Senua's Sacrifice"
          ],
          [
           "EA SPORTS FC™ 25"
          ],
          [
           "Supermarket Together"
          ],
          [
           "Company of Heroes 2"
          ],
          [
           "Dragon Age™: The Veilguard"
          ],
          [
           "FPS Chess"
          ],
          [
           "Battlefield 4™"
          ],
          [
           "Wolcen: Lords of Mayhem"
          ],
          [
           "DRAGON BALL: Sparking! ZERO"
          ],
          [
           "Spec Ops: The Line"
          ],
          [
           "Grand Theft Auto: San Andreas"
          ],
          [
           "Batman: Arkham Asylum Game of the Year Edition"
          ],
          [
           "Brotato"
          ],
          [
           "Resident Evil 7 Biohazard"
          ],
          [
           "Soundpad"
          ],
          [
           "Sleeping Dogs: Definitive Edition"
          ],
          [
           "Rivals of Aether"
          ],
          [
           "PROJECT: PLAYTIME"
          ],
          [
           "Dead Space"
          ],
          [
           "Outlast"
          ],
          [
           "Vampire: The Masquerade - Bloodhunt"
          ],
          [
           "Fishing Planet"
          ],
          [
           "Mafia: Definitive Edition"
          ],
          [
           "Rising Storm 2: Vietnam"
          ],
          [
           "Tom Clancy’s The Division™"
          ],
          [
           "Foxhole"
          ],
          [
           "The Crew™ 2"
          ],
          [
           "Barotrauma"
          ],
          [
           "eFootball™"
          ],
          [
           "Rain World"
          ],
          [
           "Age of Empires IV: Anniversary Edition"
          ],
          [
           "LEGO® Star Wars™: The Skywalker Saga"
          ],
          [
           "Brick Rigs"
          ],
          [
           "GRIS"
          ],
          [
           "Metro 2033 Redux"
          ],
          [
           "Albion Online"
          ],
          [
           "Black Squad"
          ],
          [
           "UNO"
          ],
          [
           "HoloCure - Save the Fans!"
          ],
          [
           "Friday the 13th: The Game"
          ],
          [
           "Banished"
          ],
          [
           "REMNANT II®"
          ],
          [
           "Umamusume: Pretty Derby"
          ],
          [
           "Alien: Isolation"
          ],
          [
           "Mad Max"
          ],
          [
           "DRAGON BALL FighterZ"
          ],
          [
           "STAR WARS™ Empire at War - Gold Pack"
          ],
          [
           "WorldBox - God Simulator"
          ],
          [
           "The Cycle: Frontier"
          ],
          [
           "The Witcher 2: Assassins of Kings Enhanced Edition"
          ],
          [
           "The Last of Us™ Part I"
          ],
          [
           "Mortal Kombat 11"
          ],
          [
           "GTFO"
          ],
          [
           "Your Only Move Is HUSTLE"
          ],
          [
           "Back 4 Blood"
          ],
          [
           "Wolfenstein: The New Order"
          ],
          [
           "BioShock™ Remastered"
          ],
          [
           "Minion Masters"
          ],
          [
           "Sid Meier's Civilization VII"
          ],
          [
           "Super Auto Pets"
          ],
          [
           "Town of Salem"
          ],
          [
           "XCOM: Enemy Unknown"
          ],
          [
           "Farming Simulator 22"
          ],
          [
           "Resident Evil 3"
          ],
          [
           "Batman: Arkham City - Game of the Year Edition"
          ],
          [
           "Realm Royale Reforged"
          ],
          [
           "ICARUS"
          ],
          [
           "HITMAN World of Assassination"
          ],
          [
           "Bloons TD Battles 2"
          ],
          [
           "Battlerite"
          ],
          [
           "Farming Simulator 19"
          ],
          [
           "The Long Drive"
          ],
          [
           "Lies of P"
          ],
          [
           "Plague Inc: Evolved"
          ],
          [
           "Remnant: From the Ashes"
          ],
          [
           "World of Tanks Blitz"
          ],
          [
           "Assassin's Creed® Unity"
          ],
          [
           "Dyson Sphere Program"
          ],
          [
           "Gang Beasts"
          ],
          [
           "The Walking Dead"
          ],
          [
           "ROUNDS"
          ],
          [
           "Watch_Dogs® 2"
          ],
          [
           "TEKKEN 8"
          ],
          [
           "World War 3"
          ],
          [
           "Saints Row IV: Re-Elected"
          ],
          [
           "BattleBlock Theater®"
          ],
          [
           "Resident Evil 4 (2005)"
          ],
          [
           "Jurassic World Evolution"
          ],
          [
           "Hotline Miami 2: Wrong Number"
          ],
          [
           "World of Tanks"
          ],
          [
           "Stranded Deep"
          ],
          [
           "Green Hell"
          ],
          [
           "The Binding of Isaac"
          ],
          [
           "NARAKA: BLADEPOINT"
          ],
          [
           "MiSide"
          ],
          [
           "INSIDE"
          ],
          [
           "Emily is Away"
          ],
          [
           "Max Payne 3"
          ],
          [
           "Northgard"
          ],
          [
           "This War of Mine"
          ],
          [
           "Dwarf Fortress"
          ],
          [
           "Besiege"
          ],
          [
           "Combat Master: Season 5"
          ],
          [
           "Arma Reforger"
          ],
          [
           "The Stanley Parable: Ultra Deluxe"
          ],
          [
           "Far Cry® 4"
          ],
          [
           "Mouthwashing"
          ],
          [
           "Leaf Blower Revolution - Idle Game"
          ],
          [
           "Chivalry: Medieval Warfare"
          ],
          [
           "A Way Out"
          ],
          [
           "Control Ultimate Edition"
          ],
          [
           "SOMA"
          ],
          [
           "Katana ZERO"
          ],
          [
           "EVE Online"
          ],
          [
           "Shadow of the Tomb Raider: Definitive Edition"
          ],
          [
           "Game Dev Tycoon"
          ],
          [
           "DCS World Steam Edition"
          ],
          [
           "Dragon's Dogma: Dark Arisen"
          ],
          [
           "Crossout"
          ],
          [
           "STAR WARS™ Knights of the Old Republic™"
          ],
          [
           "Car Mechanic Simulator 2018"
          ],
          [
           "FragPunk"
          ],
          [
           "Abiotic Factor"
          ],
          [
           "Killing Floor"
          ],
          [
           "Kerbal Space Program 2"
          ],
          [
           "MX Bikes"
          ],
          [
           "Bloons TD Battles"
          ],
          [
           "Prey"
          ],
          [
           "Palia"
          ],
          [
           "Unpacking"
          ],
          [
           "Pixel Gun 3D: PC Edition"
          ],
          [
           "Core Keeper"
          ],
          [
           "RuneScape ®"
          ],
          [
           "Crab Champions"
          ],
          [
           "KovaaK's"
          ],
          [
           "Fistful of Frags"
          ],
          [
           "Deep Rock Galactic: Survivor"
          ],
          [
           "Total War: SHOGUN 2"
          ],
          [
           "NBA 2K23"
          ],
          [
           "Bodycam"
          ],
          [
           "RISK: Global Domination"
          ],
          [
           "State of Decay 2: Juggernaut Edition"
          ],
          [
           "A Plague Tale: Innocence"
          ],
          [
           "Starship Troopers: Extermination"
          ],
          [
           "Broforce"
          ],
          [
           "Chivalry 2"
          ],
          [
           "DEVOUR"
          ],
          [
           "ACE COMBAT™ 7: SKIES UNKNOWN"
          ],
          [
           "Halls of Torment"
          ],
          [
           "Yu-Gi-Oh! Duel Links"
          ],
          [
           "The Sims™ 3"
          ],
          [
           "ATLAS"
          ],
          [
           "APB Reloaded"
          ],
          [
           "Quake Champions"
          ],
          [
           "Dragon Age: Origins - Ultimate Edition"
          ],
          [
           "Batman™: Arkham Origins"
          ],
          [
           "Timberborn"
          ],
          [
           "Freddy Fazbear's Pizzeria Simulator"
          ],
          [
           "PC Building Simulator"
          ],
          [
           "Slime Rancher 2"
          ],
          [
           "The Witcher: Enhanced Edition Director's Cut"
          ],
          [
           "MARVEL SNAP"
          ],
          [
           "Slay the Princess — The Pristine Cut"
          ],
          [
           "SILENT HILL 2"
          ],
          [
           "Loadout"
          ],
          [
           "Farlight 84"
          ],
          [
           "Jurassic World Evolution 2"
          ],
          [
           "Victoria 3"
          ],
          [
           "Ghostrunner"
          ],
          [
           "Banana"
          ],
          [
           "The Murder of Sonic the Hedgehog"
          ],
          [
           "Dishonored 2"
          ],
          [
           "Kingdoms and Castles"
          ],
          [
           "ENA: Dream BBQ"
          ],
          [
           "To the Moon"
          ],
          [
           "Left 4 Dead"
          ],
          [
           "Crush Crush"
          ],
          [
           "Hot Dogs, Horseshoes & Hand Grenades"
          ],
          [
           "Dying Light: The Beast"
          ],
          [
           "Borderlands: The Pre-Sequel"
          ],
          [
           "Saints Row: The Third"
          ],
          [
           "Just Cause 2"
          ],
          [
           "Crosshair X"
          ],
          [
           "STAR WARS™: Squadrons"
          ],
          [
           "Need for Speed™ Unbound"
          ],
          [
           "Neverwinter"
          ],
          [
           "Chained Together"
          ],
          [
           "Metro: Last Light Redux"
          ],
          [
           "theHunter Classic"
          ],
          [
           "They Are Billions"
          ],
          [
           "Little Nightmares"
          ],
          [
           "Persona 3 Reload"
          ],
          [
           "Street Fighter™ 6"
          ],
          [
           "CODE VEIN"
          ],
          [
           "SIGNALIS"
          ],
          [
           "Marvel’s Spider-Man: Miles Morales"
          ],
          [
           "Cruelty Squad"
          ],
          [
           "Hydroneer"
          ],
          [
           "Total War: WARHAMMER"
          ],
          [
           "One-armed robber"
          ],
          [
           "Wreckfest"
          ],
          [
           "The Test"
          ],
          [
           "DiRT Rally"
          ],
          [
           "Entropy : Zero 2"
          ],
          [
           "Temtem"
          ],
          [
           "DRAGON BALL XENOVERSE 2"
          ],
          [
           "Watch_Dogs™"
          ],
          [
           "Marvel's Guardians of the Galaxy"
          ],
          [
           "Generation Zero®"
          ],
          [
           "Phantasy Star Online 2 New Genesis"
          ],
          [
           "Spiritfarer®: Farewell Edition"
          ],
          [
           "Lords of the Fallen"
          ],
          [
           "DiRT Rally 2.0"
          ],
          [
           "BATTLETECH"
          ],
          [
           "Medieval Dynasty"
          ],
          [
           "Split Fiction"
          ],
          [
           "Empyrion - Galactic Survival"
          ],
          [
           "Trailmakers"
          ],
          [
           "HITMAN™"
          ],
          [
           "Super Animal Royale"
          ],
          [
           "Universe Sandbox"
          ],
          [
           "Age of Empires III: Definitive Edition"
          ],
          [
           "Fields of Mistria"
          ],
          [
           "EA SPORTS™ FIFA 21"
          ],
          [
           "NARUTO TO BORUTO: SHINOBI STRIKER"
          ],
          [
           "The Wolf Among Us"
          ],
          [
           "The Coffin of Andy and Leyley"
          ],
          [
           "Bastion"
          ],
          [
           "IdleOn"
          ],
          [
           "Verdun"
          ],
          [
           "DRAGON BALL Z: KAKAROT"
          ],
          [
           "Business Tour - Board Game with Online Multiplayer"
          ],
          [
           "Pathfinder: Kingmaker — Enhanced Plus Edition"
          ],
          [
           "No Rest for the Wicked"
          ],
          [
           "Torchlight II"
          ],
          [
           "Command & Conquer™ Remastered Collection"
          ],
          [
           "STAR WARS™ Knights of the Old Republic™ II - The Sith Lords™"
          ],
          [
           "Pathfinder: Wrath of the Righteous - Enhanced Edition"
          ],
          [
           "Against the Storm"
          ],
          [
           "FINAL FANTASY XV WINDOWS EDITION"
          ],
          [
           "Marvel's Avengers - The Definitive Edition"
          ],
          [
           "NARUTO SHIPPUDEN: Ultimate Ninja STORM 4"
          ],
          [
           "The Elder Scrolls III: Morrowind® Game of the Year Edition"
          ],
          [
           "ShellShock Live"
          ],
          [
           "Total War: THREE KINGDOMS"
          ],
          [
           "RuneScape: Dragonwilds"
          ],
          [
           "Return of the Obra Dinn"
          ],
          [
           "Old School RuneScape"
          ],
          [
           "Holdfast: Nations At War"
          ],
          [
           "Sanfu"
          ],
          [
           "The Talos Principle"
          ],
          [
           "POLYGON"
          ],
          [
           "Assassin's Creed 2"
          ],
          [
           "What Remains of Edith Finch"
          ],
          [
           "FINAL FANTASY VII REMAKE INTERGRADE"
          ],
          [
           "Wolfenstein II: The New Colossus"
          ],
          [
           "Risk of Rain Returns"
          ],
          [
           "Who's Your Daddy?!"
          ],
          [
           "Magic: The Gathering Arena"
          ],
          [
           "Zero Hour"
          ],
          [
           "Sonic Adventure 2"
          ],
          [
           "Brothers - A Tale of Two Sons"
          ],
          [
           "DUSK"
          ],
          [
           "DEATH STRANDING DIRECTOR'S CUT"
          ],
          [
           "The Outer Worlds"
          ],
          [
           "Clone Drone in the Danger Zone"
          ],
          [
           "Graveyard Keeper"
          ],
          [
           "Half-Life 2: Episode Two"
          ],
          [
           "Plants vs. Zombies™ Garden Warfare 2: Deluxe Edition"
          ],
          [
           "Men of War: Assault Squad 2"
          ],
          [
           "Splitgate 2 Beta"
          ],
          [
           "Call of Duty®: Modern Warfare® 2 (2009)"
          ],
          [
           "Star Trek Online"
          ],
          [
           "Party Animals"
          ],
          [
           "Indigo Park: Chapter 1"
          ],
          [
           "Total War: MEDIEVAL II – Definitive Edition"
          ],
          [
           "South Park™: The Fractured But Whole™"
          ],
          [
           "Tom Clancy's Ghost Recon® Breakpoint"
          ],
          [
           "Deus Ex: Mankind Divided"
          ],
          [
           "DOOM + DOOM II"
          ],
          [
           "SnowRunner"
          ],
          [
           "Transistor"
          ],
          [
           "Portal: Revolution"
          ],
          [
           "VTOL VR"
          ],
          [
           "The Callisto Protocol™"
          ],
          [
           "SUPERHOT"
          ],
          [
           "Nine Sols"
          ],
          [
           "Deadside"
          ],
          [
           "FINAL FANTASY VII"
          ],
          [
           "Loop Hero"
          ],
          [
           "Hi-Fi RUSH"
          ],
          [
           "Battlefield: Bad Company™ 2"
          ],
          [
           "Krunker"
          ],
          [
           "We Were Here"
          ],
          [
           "Guild Wars 2"
          ],
          [
           "Hardspace: Shipbreaker"
          ],
          [
           "Life is Strange 2"
          ],
          [
           "GUNDAM EVOLUTION"
          ],
          [
           "Mafia III: Definitive Edition"
          ],
          [
           "F1® 2021"
          ],
          [
           "Enlisted"
          ],
          [
           "Wobbly Life"
          ],
          [
           "Potion Craft: Alchemist Simulator"
          ],
          [
           "Sniper Elite 4"
          ],
          [
           "Sven Co-op"
          ],
          [
           "Counter-Strike Nexon"
          ],
          [
           "CARRION"
          ],
          [
           "Dorfromantik"
          ],
          [
           "Diablo® IV"
          ],
          [
           "L.A. Noire"
          ],
          [
           "NBA 2K22"
          ],
          [
           "Danganronpa: Trigger Happy Havoc"
          ],
          [
           "Warhammer 40,000: Rogue Trader"
          ],
          [
           "F1® 2020"
          ],
          [
           "S.T.A.L.K.E.R.: Shadow of Chernobyl"
          ],
          [
           "The Beginner's Guide"
          ],
          [
           "Mini Motorways"
          ],
          [
           "DARK SOULS™ II"
          ],
          [
           "Risk of Rain (2013)"
          ],
          [
           "Mortal Kombat 1"
          ],
          [
           "Car Mechanic Simulator 2021"
          ],
          [
           "Alan Wake"
          ],
          [
           "Outward Definitive Edition"
          ],
          [
           "Sonic Frontiers"
          ],
          [
           "Little Nightmares II"
          ],
          [
           "NEEDY STREAMER OVERLOAD"
          ],
          [
           "Spiral Knights"
          ],
          [
           "Dinkum"
          ],
          [
           "Omega Strikers"
          ],
          [
           "Mirror's Edge™"
          ],
          [
           "Aperture Desk Job"
          ],
          [
           "STALCRAFT: X"
          ],
          [
           "Notes of Soul"
          ],
          [
           "The Forever Winter"
          ],
          [
           "Bopl Battle"
          ],
          [
           "Arena Breakout: Infinite"
          ],
          [
           "Disney Dreamlight Valley"
          ],
          [
           "Age of Mythology: Extended Edition"
          ],
          [
           "LEGO® Star Wars™ - The Complete Saga"
          ],
          [
           "Age of Empires® III (2007)"
          ],
          [
           "Portal Stories: Mel"
          ],
          [
           "Portal Reloaded"
          ],
          [
           "Resident Evil 5"
          ],
          [
           "Bully: Scholarship Edition"
          ],
          [
           "Pummel Party"
          ],
          [
           "Microsoft Flight Simulator X: Steam Edition"
          ],
          [
           "Call of Duty®: Black Ops"
          ],
          [
           "Liar's Bar"
          ],
          [
           "Far Cry® New Dawn"
          ],
          [
           "Yakuza: Like a Dragon"
          ],
          [
           "NBA 2K20"
          ],
          [
           "Wasteland 3"
          ],
          [
           "GROUND BRANCH"
          ],
          [
           "Aliens: Fireteam Elite"
          ],
          [
           "CRSED: Cuisine Royale"
          ],
          [
           "The Room"
          ],
          [
           "Wayfinder"
          ],
          [
           "A Dance of Fire and Ice"
          ],
          [
           "Ultimate Chicken Horse"
          ],
          [
           "Spelunky 2"
          ],
          [
           "Battle Brothers"
          ],
          [
           "The Lord of the Rings Online™"
          ],
          [
           "REMATCH"
          ],
          [
           "魔法少女ノ魔女裁判"
          ],
          [
           "ATLYSS"
          ],
          [
           "Overcooked! 2"
          ],
          [
           "Death Must Die"
          ],
          [
           "Conqueror's Blade"
          ],
          [
           "Milk inside a bag of milk inside a bag of milk"
          ],
          [
           "Ori and the Blind Forest"
          ],
          [
           "Sonic Mania"
          ],
          [
           "Superliminal"
          ],
          [
           "BONELAB"
          ],
          [
           "Call of Duty®: WWII"
          ],
          [
           "Blackwake"
          ],
          [
           "Dungeon Defenders II"
          ],
          [
           "NBA 2K25"
          ],
          [
           "Magic Duels"
          ],
          [
           "Before Your Eyes"
          ],
          [
           "Paint the Town Red"
          ],
          [
           "SUPERVIVE"
          ],
          [
           "Forager"
          ],
          [
           "Lossless Scaling"
          ],
          [
           "Five Nights at Freddy's 2"
          ],
          [
           "DOOM: The Dark Ages"
          ],
          [
           "Deus Ex: Human Revolution - Director's Cut"
          ],
          [
           "Blood and Bacon"
          ],
          [
           "Super Meat Boy"
          ],
          [
           "Life is Strange: Before the Storm"
          ],
          [
           "Roboquest"
          ],
          [
           "Solasta: Crown of the Magister"
          ],
          [
           "Ryse: Son of Rome"
          ],
          [
           "TerraTech"
          ],
          [
           "RoboCop: Rogue City"
          ],
          [
           "Total War: ATTILA"
          ],
          [
           "Assetto Corsa Competizione"
          ],
          [
           "Night in the Woods"
          ],
          [
           "Undisputed"
          ],
          [
           "Skater XL - The Ultimate Skateboarding Game"
          ],
          [
           "Kingdom Heroes 8"
          ],
          [
           "XCOM®: Chimera Squad"
          ],
          [
           "Hitman: Absolution™"
          ],
          [
           "Far Cry® Primal"
          ],
          [
           "Street Fighter V"
          ],
          [
           "Eternal Return"
          ],
          [
           "MapleStory"
          ],
          [
           "The Walking Dead: Season Two"
          ],
          [
           "Sonic Generations Collection"
          ],
          [
           "Borderlands Game of the Year"
          ],
          [
           "BioShock™"
          ],
          [
           "Pseudoregalia"
          ],
          [
           "Sun Haven"
          ],
          [
           "Amnesia: The Dark Descent"
          ],
          [
           "Resident Evil 6"
          ],
          [
           "Half-Life: Opposing Force"
          ],
          [
           "Just Shapes & Beats"
          ],
          [
           "20 Minutes Till Dawn"
          ],
          [
           "Imperator: Rome"
          ],
          [
           "Two Point Hospital"
          ],
          [
           "Pacific Drive"
          ],
          [
           "Coral Island"
          ],
          [
           "DC Universe™ Online"
          ],
          [
           "Crypt of the NecroDancer"
          ],
          [
           "Rogue Company"
          ],
          [
           "Tom Clancy’s The Division® 2"
          ],
          [
           "KurtzPel"
          ],
          [
           "Tiny Glade"
          ],
          [
           "Wartales"
          ],
          [
           "LIMBO"
          ],
          [
           "NIGHT-RUNNERS™ PROLOGUE"
          ],
          [
           "One-armed cook"
          ],
          [
           "东北之夏"
          ],
          [
           "Spectre Divide"
          ],
          [
           "The Plan"
          ],
          [
           "Trackmania"
          ],
          [
           "NBA 2K24"
          ],
          [
           "Monster Train"
          ],
          [
           "ANIMAL WELL"
          ],
          [
           "Metaphor: ReFantazio"
          ],
          [
           "Goose Goose Duck"
          ],
          [
           "BIGFOOT"
          ],
          [
           "Into the Breach"
          ],
          [
           "Borderlands Game of the Year Enhanced"
          ],
          [
           "Assassin’s Creed Shadows"
          ],
          [
           "My Time at Portia"
          ],
          [
           "Hero Siege"
          ],
          [
           "Super Hexagon"
          ],
          [
           "DEATHLOOP"
          ],
          [
           "HUMANKIND™"
          ],
          [
           "The Looker"
          ],
          [
           "Steep™"
          ],
          [
           "The Ascent"
          ],
          [
           "High On Life"
          ],
          [
           "Half-Life 2: Episode One"
          ],
          [
           "Assassin's Creed Valhalla"
          ],
          [
           "Atomic Heart"
          ],
          [
           "Call of Duty®: Black Ops II"
          ],
          [
           "Company of Heroes 3"
          ],
          [
           "God of War Ragnarök"
          ],
          [
           "X4: Foundations"
          ],
          [
           "Total War: EMPIRE – Definitive Edition"
          ],
          [
           "Skullgirls 2nd Encore"
          ],
          [
           "Journey"
          ],
          [
           "Danganronpa 2: Goodbye Despair"
          ],
          [
           "Feed and Grow: Fish"
          ],
          [
           "VA-11 Hall-A: Cyberpunk Bartender Action"
          ],
          [
           "Tainted Grail: The Fall of Avalon"
          ],
          [
           "Golf It!"
          ],
          [
           "Dead Space (2008)"
          ],
          [
           "Crime Scene Cleaner"
          ],
          [
           "Neon White"
          ],
          [
           "Squad 44"
          ],
          [
           "Miscreated"
          ],
          [
           "TrackMania Nations Forever"
          ],
          [
           "War Robots"
          ],
          [
           "I Love You, Colonel Sanders! A Finger Lickin’ Good Dating Simulator"
          ],
          [
           "Baba Is You"
          ],
          [
           "ORION: Prelude"
          ],
          [
           "A Short Hike"
          ],
          [
           "Library Of Ruina"
          ],
          [
           "Wildermyth"
          ],
          [
           "Soulstone Survivors"
          ],
          [
           "F1® 22"
          ],
          [
           "For The King"
          ],
          [
           "Warhammer 40,000: Space Marine - Anniversary Edition"
          ],
          [
           "PlateUp!"
          ],
          [
           "Metro 2033"
          ],
          [
           "Lobotomy Corporation | Monster Management Simulation"
          ],
          [
           "Placid Plastic Duck Simulator"
          ],
          [
           "SMITE 2"
          ],
          [
           "Far Cry® 6"
          ],
          [
           "Fate Seeker II"
          ],
          [
           "Red Orchestra 2: Heroes of Stalingrad with Rising Storm"
          ],
          [
           "Predecessor"
          ],
          [
           "BioShock™ 2 Remastered"
          ],
          [
           "Nubby's Number Factory"
          ],
          [
           "Mortal Kombat X"
          ],
          [
           "missed messages."
          ],
          [
           "Project Wingman"
          ],
          [
           "Stacklands"
          ],
          [
           "My Friend Pedro"
          ],
          [
           "Our Life: Beginnings & Always"
          ],
          [
           "The Escapists 2"
          ],
          [
           "Pacify"
          ],
          [
           "Last Oasis"
          ],
          [
           "Duck Game"
          ],
          [
           "STRAFTAT"
          ],
          [
           "inZOI"
          ],
          [
           "Tiny Tina's Wonderlands"
          ],
          [
           "Marvel's Spider-Man 2"
          ],
          [
           "Gotham Knights"
          ],
          [
           "NieR Replicant™ ver.1.22474487139..."
          ],
          [
           "Marvel's Midnight Suns"
          ],
          [
           "Infestation: The New Z"
          ],
          [
           "Dead Frontier 2"
          ],
          [
           "BATTALION: Legacy"
          ],
          [
           "Dead Space™ 2"
          ],
          [
           "Tales of Arise"
          ],
          [
           "Fear Surrounds"
          ],
          [
           "Thief Simulator"
          ],
          [
           "Bloodstained: Ritual of the Night"
          ],
          [
           "Marauders"
          ],
          [
           "SCP: Containment Breach Multiplayer"
          ],
          [
           "The Culling"
          ],
          [
           "Automation - The Car Company Tycoon Game"
          ],
          [
           "Granblue Fantasy: Relink"
          ],
          [
           "Catan Universe"
          ],
          [
           "Chants of Sennaar"
          ],
          [
           "Kung Fury"
          ],
          [
           "Rocksmith® 2014 Edition REMASTERED LEARN & PLAY"
          ],
          [
           "Darkest Dungeon® II"
          ],
          [
           "Gone Home"
          ],
          [
           "Divinity: Original Sin - Enhanced Edition"
          ],
          [
           "Anno 1800"
          ],
          [
           "UBOAT"
          ],
          [
           "Choo-Choo Charles"
          ],
          [
           "Aseprite"
          ],
          [
           "Mecha BREAK"
          ],
          [
           "Fallout: A Post Nuclear Role Playing Game"
          ],
          [
           "The Texas Chain Saw Massacre"
          ],
          [
           "Call to Arms - Gates of Hell: Ostfront"
          ],
          [
           "Wobbledogs"
          ],
          [
           "RaceRoom Racing Experience"
          ],
          [
           "Moonbase Alpha"
          ],
          [
           "Townscaper"
          ],
          [
           "Stoneshard"
          ],
          [
           "Grand Theft Auto: Vice City"
          ],
          [
           "Train Simulator Classic"
          ],
          [
           "Toribash"
          ],
          [
           "ENDER LILIES: Quietus of the Knights"
          ],
          [
           "Operation: Harsh Doorstop"
          ],
          [
           "Just Cause 4 Reloaded"
          ],
          [
           "NBA 2K21"
          ],
          [
           "Quaver"
          ],
          [
           "NGU IDLE"
          ],
          [
           "Call of Duty® 4: Modern Warfare® (2007)"
          ],
          [
           "Resident Evil"
          ],
          [
           "Farming Simulator 25"
          ],
          [
           "Far Cry 3 - Blood Dragon"
          ],
          [
           "Tree of Savior (English Ver.)"
          ],
          [
           "Warhammer 40,000: Boltgun"
          ],
          [
           "Pillars of Eternity"
          ],
          [
           "Portal with RTX"
          ],
          [
           "Bendy and the Ink Machine"
          ],
          [
           "War of Rights"
          ],
          [
           "Dragon Age™ Inquisition"
          ],
          [
           "GreedFall"
          ],
          [
           "Nether: Resurrected"
          ],
          [
           "MONOPOLY® PLUS"
          ],
          [
           "Yakuza Kiwami"
          ],
          [
           "SurrounDead"
          ],
          [
           "Hyper Light Drifter"
          ],
          [
           "Alien Swarm"
          ],
          [
           "MudRunner"
          ],
          [
           "Tales from the Borderlands"
          ],
          [
           "FINAL FANTASY XVI"
          ],
          [
           "ISLANDERS"
          ],
          [
           "Spelunky"
          ],
          [
           "Viscera Cleanup Detail"
          ],
          [
           "Tower Unite"
          ],
          [
           "Shadows of Doubt"
          ],
          [
           "FINAL FANTASY X/X-2 HD Remaster"
          ],
          [
           "Gas Station Simulator"
          ],
          [
           "Inside the Backrooms"
          ],
          [
           "Dungeonborne"
          ],
          [
           "MY HERO ULTRA RUMBLE"
          ],
          [
           "Deus Ex: Game of the Year Edition"
          ],
          [
           "Strinova"
          ],
          [
           "Rogue Legacy"
          ],
          [
           "Surviving Mars"
          ],
          [
           "Trepang2"
          ],
          [
           "Thronefall"
          ],
          [
           "KARDS - The WW2 Card Game"
          ],
          [
           "Antichamber"
          ],
          [
           "Mafia II (Classic)"
          ],
          [
           "Nightingale"
          ],
          [
           "Outlast 2"
          ],
          [
           "Pineapple on pizza"
          ],
          [
           "Depth"
          ],
          [
           "Cell to Singularity - Evolution Never Ends"
          ],
          [
           "Hand Simulator"
          ],
          [
           "Bomb Rush Cyberfunk"
          ],
          [
           "Assassin's Creed™: Director's Cut Edition"
          ],
          [
           "Foundation"
          ],
          [
           "Nioh 2 – The Complete Edition"
          ],
          [
           "Death's Door"
          ],
          [
           "Sid Meier's Civilization®: Beyond Earth™"
          ],
          [
           "MechWarrior Online™ Legends"
          ],
          [
           "Shovel Knight: Treasure Trove"
          ],
          [
           "LISA: The Painful"
          ],
          [
           "Bayonetta"
          ],
          [
           "Gloomhaven"
          ],
          [
           "Warhammer 40,000: Inquisitor - Martyr"
          ],
          [
           "The Walking Dead: The Telltale Definitive Series"
          ],
          [
           "Descenders"
          ],
          [
           "The Room Two"
          ],
          [
           "The Last of Us™ Part II Remastered"
          ],
          [
           "Sheepy: A Short Adventure"
          ],
          [
           "Darwin Project"
          ],
          [
           "HELLDIVERS™ Dive Harder Edition"
          ],
          [
           "JUMP FORCE"
          ],
          [
           "Vampire: The Masquerade - Bloodlines"
          ],
          [
           "Demonologist"
          ],
          [
           "Artifact"
          ],
          [
           "Total War: NAPOLEON – Definitive Edition"
          ],
          [
           "Transport Fever 2"
          ],
          [
           "Nodebuster"
          ],
          [
           "Doki Doki Literature Club Plus!"
          ],
          [
           "Alice: Madness Returns"
          ],
          [
           "Sonic Adventure DX"
          ],
          [
           "The Day Before"
          ],
          [
           "A Game About Digging A Hole"
          ],
          [
           "STAR WARS™ Republic Commando™"
          ],
          [
           "Dawn of Man"
          ],
          [
           "OBS Studio"
          ],
          [
           "SpeedRunners"
          ],
          [
           "CrossCode"
          ],
          [
           "Age of Wonders 4"
          ],
          [
           "Call of Juarez: Gunslinger"
          ],
          [
           "Mass Effect (2007)"
          ],
          [
           "Microsoft Flight Simulator 2024"
          ],
          [
           "Peglin"
          ],
          [
           "Day of Infamy"
          ],
          [
           "Sky: Children of the Light"
          ],
          [
           "Ranch Simulator: Build, Hunt, Farm"
          ],
          [
           "ABZU"
          ],
          [
           "Football Manager 2021"
          ],
          [
           "Call of Duty®: Black Ops Cold War"
          ],
          [
           "Police Simulator: Patrol Officers"
          ],
          [
           "Tropico 6"
          ]
         ],
         "hovertemplate": "PCA Component 1=%{x}<br>PCA Component 2=%{y}<br>PCA Component 3=%{z}<br>title=%{customdata[0]}<br>cluster=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": {
           "bdata": "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",
           "dtype": "i4"
          },
          "coloraxis": "coloraxis",
          "opacity": 0.6,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "type": "scatter3d",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "cluster"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "PCA Component 1"
          }
         },
         "yaxis": {
          "title": {
           "text": "PCA Component 2"
          }
         },
         "zaxis": {
          "title": {
           "text": "PCA Component 3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Game Clusters Based on Text Content (3D PCA) - Top 1000 by Review Count"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "texts = []\n",
    "titles = []\n",
    "for game in all_games:\n",
    "    text = (game.get('about_this_game', '') + ' ' + \n",
    "            game.get('description', ''))\n",
    "    texts.append(text)\n",
    "    titles.append(game.get('title', 'Unknown'))\n",
    "\n",
    "print(f\"Prepared {len(texts)} text documents\")\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(texts)\n",
    "print(f\"Vectorized to shape: {X.shape}\")\n",
    "\n",
    "# Cluster\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "print(\"Clustering completed\")\n",
    "\n",
    "# Calculate silhouette score\n",
    "# Commented since it's slow to compute\n",
    "# sil_score = silhouette_score(X, clusters)\n",
    "# print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "\n",
    "# Filter top 1000 games by review_count for visualization only\n",
    "top_indices = sorted(range(len(all_games)), key=lambda i: all_games[i].get('review_count') or 0, reverse=True)[:1000]\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_pca = pca.fit_transform(X[top_indices].toarray())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x': X_pca[:, 0],\n",
    "    'y': X_pca[:, 1],\n",
    "    'z': X_pca[:, 2],\n",
    "    'cluster': clusters[top_indices],\n",
    "    'title': [titles[i] for i in top_indices]\n",
    "})\n",
    "\n",
    "fig = px.scatter_3d(df, x='x', y='y', z='z', color='cluster', \n",
    "                    hover_data=['title'], \n",
    "                    title='Game Clusters Based on Text Content (3D PCA) - Top 1000 by Review Count',\n",
    "                    labels={'x': 'PCA Component 1', 'y': 'PCA Component 2', 'z': 'PCA Component 3'},\n",
    "                    size_max=3, opacity=0.6)\n",
    "from IPython.display import display\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa8573a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "(game, levels, time, level, play)\n",
      "28347 games\n",
      "1. Red Dead Redemption 2 (rating: 94.0, votes: 265521)\n",
      "2. Call of Duty® (rating: 43.0, votes: 226321)\n",
      "3. Wallpaper Engine (rating: 97.0, votes: 213944)\n",
      "4. Geometry Dash (rating: 92.0, votes: 198863)\n",
      "5. BeamNG.drive (rating: 96.0, votes: 177744)\n",
      "6. People Playground (rating: 97.0, votes: 164703)\n",
      "7. The Elder Scrolls V: Skyrim Special Edition (rating: 96.0, votes: 119501)\n",
      "8. Call of Duty®: Black Ops III (rating: 91.0, votes: 110569)\n",
      "9. Aimlabs (rating: 78.0, votes: 63512)\n",
      "10. Cuphead (rating: 94.0, votes: 60045)\n",
      "\n",
      "Cluster 1\n",
      "(world, game, adventure, rpg, explore)\n",
      "17746 games\n",
      "1. Terraria (rating: 95.0, votes: 567973)\n",
      "2. Baldur's Gate 3 (rating: 95.0, votes: 420753)\n",
      "3. ELDEN RING (rating: 93.0, votes: 414562)\n",
      "4. Warframe (rating: 74.0, votes: 277820)\n",
      "5. The Witcher 3: Wild Hunt (rating: 95.0, votes: 227449)\n",
      "6. Fallout 4 (rating: 83.0, votes: 169360)\n",
      "7. Hollow Knight (rating: 96.0, votes: 157655)\n",
      "8. Undertale (rating: 96.0, votes: 151595)\n",
      "9. New World: Aeternum (rating: 56.0, votes: 142785)\n",
      "10. Sea of Thieves: 2025 Edition (rating: 80.0, votes: 141385)\n",
      "\n",
      "Cluster 2\n",
      "(vr, virtual, game, experience, reality)\n",
      "3927 games\n",
      "1. VRChat (rating: 69.0, votes: 166100)\n",
      "2. Half-Life: Alyx (rating: 97.0, votes: 58910)\n",
      "3. Pavlov (rating: 53.0, votes: 30799)\n",
      "4. BONEWORKS (rating: 93.0, votes: 29194)\n",
      "5. Hot Dogs, Horseshoes & Hand Grenades (rating: 96.0, votes: 18766)\n",
      "6. VTOL VR (rating: 97.0, votes: 15880)\n",
      "7. High On Life (rating: 85.0, votes: 11884)\n",
      "8. FIVE NIGHTS AT FREDDY'S: HELP WANTED (rating: 94.0, votes: 7330)\n",
      "9. SEGA Mega Drive and Genesis Classics (rating: 56.0, votes: 7099)\n",
      "10. The Elder Scrolls V: Skyrim VR (rating: 77.0, votes: 7086)\n",
      "\n",
      "Cluster 3\n",
      "(puzzle, puzzles, game, solve, levels)\n",
      "7900 games\n",
      "1. OneShot (rating: 97.0, votes: 29533)\n",
      "2. Unpacking (rating: 92.0, votes: 21070)\n",
      "3. The Talos Principle (rating: 93.0, votes: 16710)\n",
      "4. Portal: Revolution (rating: 97.0, votes: 15903)\n",
      "5. Portal Reloaded (rating: 93.0, votes: 13929)\n",
      "6. Superliminal (rating: 93.0, votes: 13364)\n",
      "7. The Looker (rating: 97.0, votes: 11902)\n",
      "8. Baba Is You (rating: 96.0, votes: 11471)\n",
      "9. Inside the Backrooms (rating: 61.0, votes: 10036)\n",
      "10. A Little to the Left (rating: 89.0, votes: 8556)\n",
      "\n",
      "Cluster 4\n",
      "(cards, card, deck, game, play)\n",
      "2542 games\n",
      "1. Balatro (rating: 97.0, votes: 90659)\n",
      "2. Inscryption (rating: 96.0, votes: 72307)\n",
      "3. Slay the Spire (rating: 96.0, votes: 68394)\n",
      "4. Yu-Gi-Oh! Master Duel (rating: 49.0, votes: 45546)\n",
      "5. TCG Card Shop Simulator (rating: 94.0, votes: 29331)\n",
      "6. UNO (rating: 37.0, votes: 25495)\n",
      "7. Minion Masters (rating: 75.0, votes: 24495)\n",
      "8. FragPunk (rating: 77.0, votes: 21451)\n",
      "9. Yu-Gi-Oh! Duel Links (rating: 66.0, votes: 20046)\n",
      "10. MARVEL SNAP (rating: 67.0, votes: 19284)\n",
      "\n",
      "Cluster 5\n",
      "(enemies, game, weapons, enemy, shooter)\n",
      "16895 games\n",
      "1. HELLDIVERS™ 2 (rating: 62.0, votes: 593251)\n",
      "2. PUBG: BATTLEGROUNDS (rating: 70.0, votes: 436239)\n",
      "3. Marvel Rivals (rating: 63.0, votes: 237779)\n",
      "4. Deep Rock Galactic (rating: 95.0, votes: 163568)\n",
      "5. Risk of Rain 2 (rating: 90.0, votes: 150121)\n",
      "6. Vampire Survivors (rating: 95.0, votes: 122830)\n",
      "7. ULTRAKILL (rating: 96.0, votes: 121766)\n",
      "8. Borderlands 2 (rating: 88.0, votes: 121171)\n",
      "9. DOOM Eternal (rating: 88.0, votes: 117919)\n",
      "10. Hunt: Showdown 1896 (rating: 72.0, votes: 90854)\n",
      "\n",
      "Cluster 6\n",
      "(build, game, city, resources, new)\n",
      "13388 games\n",
      "1. Rust (rating: 82.0, votes: 501936)\n",
      "2. Stardew Valley (rating: 98.0, votes: 366195)\n",
      "3. Cyberpunk 2077 (rating: 94.0, votes: 353121)\n",
      "4. Lethal Company (rating: 91.0, votes: 269445)\n",
      "5. ARK: Survival Evolved (rating: 80.0, votes: 250166)\n",
      "6. Valheim (rating: 88.0, votes: 247945)\n",
      "7. Unturned (rating: 83.0, votes: 219536)\n",
      "8. The Forest (rating: 94.0, votes: 172139)\n",
      "9. No Man's Sky (rating: 90.0, votes: 170786)\n",
      "10. DayZ (rating: 87.0, votes: 170769)\n",
      "\n",
      "Cluster 7\n",
      "(players, game, multiplayer, play, online)\n",
      "12717 games\n",
      "1. Dota 2 (rating: 72.0, votes: 809179)\n",
      "2. Tom Clancy's Rainbow Six® Siege X (rating: 69.0, votes: 734262)\n",
      "3. Team Fortress 2 (rating: 94.0, votes: 714797)\n",
      "4. Grand Theft Auto V Legacy (rating: 93.0, votes: 570531)\n",
      "5. Garry's Mod (rating: 96.0, votes: 508654)\n",
      "6. Apex Legends™ (rating: 64.0, votes: 429334)\n",
      "7. Destiny 2 (rating: 30.0, votes: 373269)\n",
      "8. Among Us (rating: 91.0, votes: 364441)\n",
      "9. Phasmophobia (rating: 91.0, votes: 338209)\n",
      "10. War Thunder (rating: 72.0, votes: 281826)\n",
      "\n",
      "Cluster 8\n",
      "(game, story, horror, life, novel)\n",
      "18578 games\n",
      "1. Counter-Strike 2 (rating: 80.0, votes: 2428078)\n",
      "2. Dead by Daylight (rating: 75.0, votes: 237291)\n",
      "3. Doki Doki Literature Club! (rating: 95.0, votes: 122674)\n",
      "4. SCP: Secret Laboratory (rating: 88.0, votes: 88733)\n",
      "5. Life is Strange - Episode 1 (rating: 98.0, votes: 74666)\n",
      "6. Stray (rating: 95.0, votes: 74491)\n",
      "7. Firewatch (rating: 92.0, votes: 53945)\n",
      "8. Helltaker (rating: 95.0, votes: 53286)\n",
      "9. Resident Evil 4 (rating: 97.0, votes: 52407)\n",
      "10. Tomb Raider (rating: 95.0, votes: 48560)\n",
      "\n",
      "Cluster 9\n",
      "(game, games, story, rpg, features)\n",
      "1527 games\n",
      "1. Sanfu (rating: 84.0, votes: 16720)\n",
      "2. 古龙风云录 (rating: 62.0, votes: 8357)\n",
      "3. 魔女的夜宴 (rating: 95.0, votes: 8089)\n",
      "4. Kalpa of Sword (rating: 35.0, votes: 6551)\n",
      "5. 古剑奇谭(GuJian) (rating: 86.0, votes: 4979)\n",
      "6. 枝江往事 (rating: 96.0, votes: 4871)\n",
      "7. Swaying Girl (rating: 89.0, votes: 4851)\n",
      "8. 再刷一把 PlayAgain (rating: 66.0, votes: 4419)\n",
      "9. 我的小鲨鱼 (rating: 100.0, votes: 4235)\n",
      "10. 妄想破绽 Broken Delusion (rating: 60.0, votes: 3906)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "cluster_topics = {}\n",
    "for cluster_id in range(NUM_CLUSTERS):\n",
    "    cluster_indices = [i for i, c in enumerate(clusters) if c == cluster_id]\n",
    "    cluster_tfidf = X[cluster_indices]\n",
    "    avg_tfidf = cluster_tfidf.mean(axis=0).A1  # average TF-IDF per word\n",
    "    top_indices = avg_tfidf.argsort()[-10:][::-1]  # top 10 words\n",
    "    top_words = [feature_names[i] for i in top_indices]\n",
    "    cluster_topics[cluster_id] = top_words\n",
    "\n",
    "    # Get cluster games and sort by review_count\n",
    "    cluster_games = [game for game, c in zip(all_games, clusters) if c == cluster_id]\n",
    "    sorted_games = sorted(cluster_games, key=lambda g: g.get('review_count') or 0, reverse=True)\n",
    "\n",
    "    # Take up to 10 unique titles\n",
    "    sample = []\n",
    "    seen_titles = set()\n",
    "    for g in sorted_games:\n",
    "        title = g['title']\n",
    "        if title not in seen_titles:\n",
    "            sample.append(g)\n",
    "            seen_titles.add(title)\n",
    "        if len(sample) >= 10:\n",
    "            break\n",
    "\n",
    "    print(f\"Cluster {cluster_id}\")\n",
    "    print(f\"({', '.join(top_words[:5])})\")  # Show top 5 words as topics\n",
    "    print(f\"{len(cluster_games)} games\")\n",
    "\n",
    "    for i, g in enumerate(sample, 1):\n",
    "        rating = g.get('review_score', 'N/A')\n",
    "        votes = g.get('review_count') or 0\n",
    "        print(f\"{i}. {g['title']} (rating: {rating}, votes: {votes})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f4122",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a5e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"mature_labels.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    mature_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a40a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_cluster(all_games, clusters, cluster_id):\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    for game, c in zip(all_games, clusters):\n",
    "        if c != cluster_id:\n",
    "            continue\n",
    "\n",
    "        appid = str(game[\"app_id\"])\n",
    "        if appid not in mature_labels:\n",
    "            continue\n",
    "\n",
    "        label = mature_labels[appid]\n",
    "\n",
    "        text = game.get(\"about_this_game\") or \"\"\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        texts.append(text)\n",
    "        labels.append(int(bool(label)))\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "216d06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "def train_classifier(texts, labels, cluster_id):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=\"english\"\n",
    "        )),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "    with open(f\"classificators/mature_classifier_cluster_{cluster_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec34f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_game_mature(game, model):\n",
    "    text = game.get(\"about_this_game\", \"\") or \"\"\n",
    "    return model.predict([text])[0]\n",
    "\n",
    "def classifier_stats(model, cluster_id):\n",
    "    errors = 0\n",
    "    total = 0\n",
    "\n",
    "    for game, c in zip(all_games, clusters):\n",
    "        if c != cluster_id:\n",
    "            continue\n",
    "\n",
    "        appid = str(game[\"app_id\"])\n",
    "        if appid not in mature_labels:\n",
    "            continue\n",
    "\n",
    "        label = mature_labels[appid]\n",
    "        total += 1\n",
    "        pred_label = predict_game_mature(game, model)\n",
    "        if pred_label != label:\n",
    "            errors += 1\n",
    "            # print(f\"AppID: {appid}, Title: {game['title']}\")\n",
    "            # print(f\"True Label: {label}, Predicted: {pred_label}\")\n",
    "            # print()    \n",
    "\n",
    "    print(f\"Total games checked: {total}, Errors: {errors}, Error Rate: {errors/total:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cluster_id in range(NUM_CLUSTERS):\n",
    "#     print(f\"Training classifier for cluster {cluster_id}...\")\n",
    "#     texts, labels = prepare_data_for_cluster(all_games, clusters, cluster_id)\n",
    "#     if len(texts) < 10:\n",
    "#         print(f\"Not enough data for cluster {cluster_id}, skipping...\")\n",
    "#         continue\n",
    "\n",
    "#     model = train_classifier(texts, labels, cluster_id)\n",
    "#     classifier_stats(model, cluster_id)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e6dae",
   "metadata": {},
   "source": [
    "## Transformer Analysis with Unified PEGI/ESRB Labels\n",
    "\n",
    "Using the unified maturity labels from official PEGI/ESRB ratings.\n",
    "Training on 14,713 games with verified ratings (76.5% PEGI, 23.5% ESRB).\n",
    "\n",
    "Classification approach:\n",
    "- **Multi-class Tier Prediction**: Predict exact age rating tier (0-3)\n",
    "  - Tier 0: Everyone\n",
    "  - Tier 1: Teen  \n",
    "  - Tier 2: Mature\n",
    "  - Tier 3: Adults Only\n",
    "- **Data**: Games with official PEGI/ESRB ratings only\n",
    "\n",
    "Comparing two approaches:\n",
    "1. **Global Model**: Direct tier classification from text\n",
    "2. **Cluster-Aware Model**: Cluster assignment followed by per-cluster tier classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cce967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubeu\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4de6c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "068e413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14713 unified maturity labels from PEGI/ESRB ratings\n",
      "\n",
      "Total samples for transformer: 13495\n",
      "Task: 4-class tier prediction (0=Everyone, 1=Teen, 2=Mature, 3=Adults Only)\n",
      "\n",
      "Tier distribution:\n",
      "  Tier 0 (Everyone): 6331 (46.9%)\n",
      "  Tier 1 (Teen): 3861 (28.6%)\n",
      "  Tier 2 (Mature): 2317 (17.2%)\n",
      "  Tier 3 (Adults Only): 986 (7.3%)\n",
      "\n",
      "Source distribution:\n",
      "  PEGI: 10331 (76.6%)\n",
      "  ESRB: 3164 (23.4%)\n"
     ]
    }
   ],
   "source": [
    "# Load unified maturity labels (PEGI/ESRB)\n",
    "with open(\"data/unified_maturity_labels.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    unified_labels = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(unified_labels)} unified maturity labels from PEGI/ESRB ratings\")\n",
    "\n",
    "# Prepare dataset for transformer training\n",
    "def prepare_transformer_data(all_games, unified_labels, use_description=True):\n",
    "    \"\"\"Prepare texts and labels for transformer training using unified PEGI/ESRB data.\"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    app_ids = []\n",
    "    tiers = []\n",
    "    sources = []\n",
    "    \n",
    "    for game in all_games:\n",
    "        appid = str(game[\"app_id\"])\n",
    "        if appid not in unified_labels:\n",
    "            continue\n",
    "        \n",
    "        label_data = unified_labels[appid]\n",
    "        tier = label_data['tier']\n",
    "        \n",
    "        about = game.get(\"about_this_game\") or \"\"\n",
    "        desc = game.get(\"description\") or \"\"\n",
    "        \n",
    "        if use_description:\n",
    "            text = f\"{about} {desc}\".strip()\n",
    "        else:\n",
    "            text = about.strip()\n",
    "        \n",
    "        if not text:\n",
    "            continue\n",
    "        \n",
    "        texts.append(text)\n",
    "        # Multi-class classification: Predict tier directly (0-3)\n",
    "        # Tier 0 (Everyone), Tier 1 (Teen), Tier 2 (Mature), Tier 3 (Adults Only)\n",
    "        labels.append(tier)\n",
    "        app_ids.append(appid)\n",
    "        tiers.append(tier)\n",
    "        sources.append(label_data['source'])\n",
    "    \n",
    "    return texts, labels, app_ids, tiers, sources\n",
    "\n",
    "# Prepare the full dataset\n",
    "all_texts, all_labels, all_app_ids, all_tiers, all_sources = prepare_transformer_data(all_games, unified_labels)\n",
    "\n",
    "print(f\"\\nTotal samples for transformer: {len(all_texts)}\")\n",
    "print(f\"Task: 4-class tier prediction (0=Everyone, 1=Teen, 2=Mature, 3=Adults Only)\")\n",
    "\n",
    "# Show tier distribution\n",
    "from collections import Counter\n",
    "tier_counts = Counter(all_tiers)\n",
    "tier_names = {0: \"Everyone\", 1: \"Teen\", 2: \"Mature\", 3: \"Adults Only\"}\n",
    "print(\"\\nTier distribution:\")\n",
    "for tier in sorted(tier_counts.keys()):\n",
    "    count = tier_counts[tier]\n",
    "    print(f\"  Tier {tier} ({tier_names[tier]}): {count} ({100*count/len(all_tiers):.1f}%)\")\n",
    "\n",
    "# Show source distribution\n",
    "source_counts = Counter(all_sources)\n",
    "print(\"\\nSource distribution:\")\n",
    "for source, count in source_counts.items():\n",
    "    print(f\"  {source.upper()}: {count} ({100*count/len(all_sources):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c02a9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning:\n",
      "\n",
      "`huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kubeu\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset for game text classification\n",
    "class GameTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Simple Transformer Classifier using DistilBERT\n",
    "import logging\n",
    "# Suppress the expected warning about unused weights\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4, dropout=0.5):  # Default to 4 classes for tier prediction\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Add additional dropout layer\n",
    "        self.dropout2 = nn.Dropout(dropout * 0.8)  # Secondary dropout\n",
    "        # Add intermediate layer for better regularization\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.intermediate = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.classifier = nn.Linear(hidden_size // 2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        pooled = self.dropout(pooled)\n",
    "        # Add intermediate layer with activation and dropout\n",
    "        hidden = self.intermediate(pooled)\n",
    "        hidden = self.relu(hidden)\n",
    "        hidden = self.dropout2(hidden)\n",
    "        logits = self.classifier(hidden)\n",
    "        return logits\n",
    "\n",
    "print(\"Tokenizer loaded\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(model, train_loader, val_loader, epochs=3, lr=2e-5, class_weights=None):\n",
    "    \"\"\"Train a transformer model and return training history with early stopping.\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    \n",
    "    # Use class weights if provided (for imbalanced data)\n",
    "    if class_weights is not None:\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Learning rate scheduler - reduce LR when validation loss plateaus\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-7\n",
    "    )\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    early_stop_patience = 4  # Stop if no improvement for 4 epochs\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='macro')  # Use macro for multi-class\n",
    "        \n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model state\n",
    "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f} ✓ (best)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f} (no improvement {patience_counter}/{early_stop_patience})\")\n",
    "            \n",
    "            if patience_counter >= early_stop_patience:\n",
    "                print(f\"\\nEarly stopping triggered after epoch {epoch+1}\")\n",
    "                print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "                break\n",
    "    \n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        model = model.to(device)\n",
    "        print(\"Restored best model from validation\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate model and return predictions and true labels.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_scores = [] \n",
    "    \n",
    "    # Weight matrix for class relationships\n",
    "    W = torch.tensor([\n",
    "        [1.0, 0.5, 0.0, 0.0],\n",
    "        [0.5, 1.0, 0.5, 0.0],\n",
    "        [0.0, 0.5, 1.0, 0.5],\n",
    "        [0.0, 0.0, 0.5, 1.0],\n",
    "    ]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # new scoring mechanism\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            batch_score = torch.sum(probs * W[labels], dim=1)\n",
    "            \n",
    "            all_scores.extend(batch_score.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return all_preds, all_labels, all_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96149bcb",
   "metadata": {},
   "source": [
    "### Model 1: Global Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "442bf1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Model - Train: 9716, Val: 1080, Test: 2699\n",
      "\n",
      "Train distribution:\n",
      "  Tier 0 (Everyone): 4558 (46.9%)\n",
      "  Tier 1 (Teen): 2780 (28.6%)\n",
      "  Tier 2 (Mature): 1668 (17.2%)\n",
      "  Tier 3 (Adults Only): 710 (7.3%)\n",
      "\n",
      "Val distribution:\n",
      "  Tier 0 (Everyone): 507 (46.9%)\n",
      "  Tier 1 (Teen): 309 (28.6%)\n",
      "  Tier 2 (Mature): 185 (17.1%)\n",
      "  Tier 3 (Adults Only): 79 (7.3%)\n",
      "\n",
      "Test distribution:\n",
      "  Tier 0 (Everyone): 1266 (46.9%)\n",
      "  Tier 1 (Teen): 772 (28.6%)\n",
      "  Tier 2 (Mature): 464 (17.2%)\n",
      "  Tier 3 (Adults Only): 197 (7.3%)\n",
      "Dataloaders created - Train batches: 608, Val batches: 68\n",
      "Using MAX_LENGTH=512 tokens (DistilBERT maximum)\n"
     ]
    }
   ],
   "source": [
    "# Split data for global model with stratified splits to preserve tier distribution\n",
    "X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(\n",
    "    all_texts, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "X_train_global, X_val_global, y_train_global, y_val_global = train_test_split(\n",
    "    X_train_global, y_train_global, test_size=0.1, random_state=42, stratify=y_train_global\n",
    ")\n",
    "\n",
    "print(f\"Global Model - Train: {len(X_train_global)}, Val: {len(X_val_global)}, Test: {len(X_test_global)}\")\n",
    "\n",
    "# Show tier distribution in each split\n",
    "from collections import Counter\n",
    "tier_names = {0: \"Everyone\", 1: \"Teen\", 2: \"Mature\", 3: \"Adults Only\"}\n",
    "for split_name, split_labels in [(\"Train\", y_train_global), (\"Val\", y_val_global), (\"Test\", y_test_global)]:\n",
    "    tier_counts = Counter(split_labels)\n",
    "    print(f\"\\n{split_name} distribution:\")\n",
    "    for tier in sorted(tier_counts.keys()):\n",
    "        count = tier_counts[tier]\n",
    "        print(f\"  Tier {tier} ({tier_names[tier]}): {count} ({100*count/len(split_labels):.1f}%)\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512  # DistilBERT maximum - captures 85.7% of descriptions fully (14.3% truncated)\n",
    "\n",
    "train_dataset_global = GameTextDataset(X_train_global, y_train_global, tokenizer, MAX_LENGTH)\n",
    "val_dataset_global = GameTextDataset(X_val_global, y_val_global, tokenizer, MAX_LENGTH)\n",
    "test_dataset_global = GameTextDataset(X_test_global, y_test_global, tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_loader_global = DataLoader(train_dataset_global, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_global = DataLoader(val_dataset_global, batch_size=BATCH_SIZE)\n",
    "test_loader_global = DataLoader(test_dataset_global, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Dataloaders created - Train batches: {len(train_loader_global)}, Val batches: {len(val_loader_global)}\")\n",
    "print(f\"Using MAX_LENGTH={MAX_LENGTH} tokens (DistilBERT maximum)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cf38651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing token lengths in game descriptions...\n",
      "\n",
      "Token length statistics (n=1000):\n",
      "  Min: 27\n",
      "  Max: 1574\n",
      "  Mean: 333.8\n",
      "  Median: 291.0\n",
      "  75th percentile: 427.2\n",
      "  90th percentile: 566.2\n",
      "  95th percentile: 675.0\n",
      "  99th percentile: 1006.0\n",
      "\n",
      "% of texts that would be truncated at different lengths:\n",
      "  256 tokens: 58.9% truncated (avg 187 tokens lost)\n",
      "  512 tokens: 13.9% truncated (avg 176 tokens lost)\n",
      "  768 tokens: 3.0% truncated (avg 220 tokens lost)\n",
      "  1024 tokens: 0.9% truncated (avg 240 tokens lost)\n"
     ]
    }
   ],
   "source": [
    "# Check token lengths in the dataset\n",
    "print(\"Analyzing token lengths in game descriptions...\")\n",
    "text_lengths = []\n",
    "for text in all_texts[:1000]:  # Sample first 1000\n",
    "    tokens = tokenizer(text, truncation=False)['input_ids']\n",
    "    text_lengths.append(len(tokens))\n",
    "\n",
    "import numpy as np\n",
    "print(f\"\\nToken length statistics (n={len(text_lengths)}):\")\n",
    "print(f\"  Min: {min(text_lengths)}\")\n",
    "print(f\"  Max: {max(text_lengths)}\")\n",
    "print(f\"  Mean: {np.mean(text_lengths):.1f}\")\n",
    "print(f\"  Median: {np.median(text_lengths):.1f}\")\n",
    "print(f\"  75th percentile: {np.percentile(text_lengths, 75):.1f}\")\n",
    "print(f\"  90th percentile: {np.percentile(text_lengths, 90):.1f}\")\n",
    "print(f\"  95th percentile: {np.percentile(text_lengths, 95):.1f}\")\n",
    "print(f\"  99th percentile: {np.percentile(text_lengths, 99):.1f}\")\n",
    "\n",
    "print(f\"\\n% of texts that would be truncated at different lengths:\")\n",
    "for limit in [256, 512, 768, 1024]:\n",
    "    pct = sum(1 for l in text_lengths if l > limit) / len(text_lengths) * 100\n",
    "    avg_lost = np.mean([max(0, l - limit) for l in text_lengths if l > limit]) if any(l > limit for l in text_lengths) else 0\n",
    "    print(f\"  {limit} tokens: {pct:.1f}% truncated (avg {avg_lost:.0f} tokens lost)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00243432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Global Transformer Model for tier prediction...\n",
      "Changes: Dropout 0.5, Early stopping, Gradient clipping, Intermediate layer\n",
      "Task: 4-class classification (Tier 0-3)\n",
      "Class weights (reduced):\n",
      "  Tier 0 (Everyone): 0.73\n",
      "  Tier 1 (Teen): 0.93\n",
      "  Tier 2 (Mature): 1.21\n",
      "  Tier 3 (Adults Only): 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "The following layers were not sharded: transformer.layer.*.attention.q_lin.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias, transformer.layer.*.attention.k_lin.bias, embeddings.LayerNorm.bias, transformer.layer.*.attention.k_lin.weight, transformer.layer.*.output_layer_norm.weight, transformer.layer.*.ffn.lin*.bias, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.sa_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.q_lin.bias, embeddings.LayerNorm.weight, embeddings.word_embeddings.weight\n",
      "Epoch 1/1 - Training:   0%|          | 2/608 [00:33<2:46:59, 16.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Tier \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier_names[tier]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m global_model = TransformerClassifier(num_classes=\u001b[32m4\u001b[39m, dropout=\u001b[32m0.5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m global_model, global_history = \u001b[43mtrain_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Max epochs, but early stopping will kick in\u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced from 2e-5 for more stable training\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Save the global model\u001b[39;00m\n\u001b[32m     42\u001b[39m torch.save(global_model.state_dict(), global_model_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mtrain_transformer\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, lr, class_weights)\u001b[39m\n\u001b[32m     34\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m     36\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     39\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mTransformerClassifier.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     pooled = outputs.last_hidden_state[:, \u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# CLS token\u001b[39;00m\n\u001b[32m     51\u001b[39m     pooled = \u001b[38;5;28mself\u001b[39m.dropout(pooled)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:724\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    720\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    721\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    722\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:531\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    529\u001b[39m     all_hidden_states = all_hidden_states + (hidden_state,)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:484\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    481\u001b[39m sa_output = \u001b[38;5;28mself\u001b[39m.sa_layer_norm(sa_output + x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m ffn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    485\u001b[39m ffn_output: torch.Tensor = \u001b[38;5;28mself\u001b[39m.output_layer_norm(ffn_output + sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    487\u001b[39m output = (ffn_output,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:418\u001b[39m, in \u001b[36mFFN.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\transformers\\pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:423\u001b[39m, in \u001b[36mFFN.ff_chunk\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    421\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    422\u001b[39m x = \u001b[38;5;28mself\u001b[39m.activation(x)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kubeu\\anaconda3\\envs\\steamscraper-conda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train or load global transformer model\n",
    "global_model_path = \"classificators/transformer_global_model_v3_tier.pt\"  # New version for tier prediction\n",
    "\n",
    "if not FORCE_RETRAIN and os.path.exists(global_model_path):\n",
    "    print(\"Loading existing Global Transformer Model...\")\n",
    "    global_model = TransformerClassifier(num_classes=4)  # Changed to 4 for tier prediction\n",
    "    global_model.load_state_dict(torch.load(global_model_path, map_location=device))\n",
    "    global_model = global_model.to(device)\n",
    "    # Create dummy history for compatibility\n",
    "    global_history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "    print(\"Global model loaded!\")\n",
    "else:\n",
    "    print(\"Training Global Transformer Model for tier prediction...\")\n",
    "    print(\"Changes: Dropout 0.5, Early stopping, Gradient clipping, Intermediate layer\")\n",
    "    print(\"Task: 4-class classification (Tier 0-3)\")\n",
    "    \n",
    "    # Calculate class weights for imbalanced data (lighter weights to reduce overfitting)\n",
    "    n_samples = len(y_train_global)\n",
    "    tier_counts = Counter(y_train_global)\n",
    "    # Reduce weight impact by using sqrt\n",
    "    class_weights = []\n",
    "    for tier in range(4):\n",
    "        if tier in tier_counts:\n",
    "            weight = (n_samples / (4 * tier_counts[tier])) ** 0.5\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        class_weights.append(weight)\n",
    "    print(f\"Class weights (reduced):\")\n",
    "    for tier, weight in enumerate(class_weights):\n",
    "        print(f\"  Tier {tier} ({tier_names[tier]}): {weight:.2f}\")\n",
    "    \n",
    "    global_model = TransformerClassifier(num_classes=4, dropout=0.5)\n",
    "    global_model, global_history = train_transformer(\n",
    "        global_model, \n",
    "        train_loader_global, \n",
    "        val_loader_global, \n",
    "        epochs=1,  # Max epochs, but early stopping will kick in\n",
    "        lr=5e-6,  # Reduced from 2e-5 for more stable training\n",
    "        class_weights=class_weights\n",
    "    )\n",
    "    # Save the global model\n",
    "    torch.save(global_model.state_dict(), global_model_path)\n",
    "    print(\"Global model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d918f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 169/169 [00:38<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Global Transformer Model Results (Tier Prediction) ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "   Everyone (T0)       0.70      0.78      0.74      1272\n",
      "       Teen (T1)       0.47      0.53      0.50       769\n",
      "     Mature (T2)       0.41      0.32      0.36       464\n",
      "Adults Only (T3)       0.50      0.16      0.24       199\n",
      "\n",
      "        accuracy                           0.59      2704\n",
      "       macro avg       0.52      0.45      0.46      2704\n",
      "    weighted avg       0.57      0.59      0.57      2704\n",
      "\n",
      "Test Accuracy: 0.5854\n",
      "Test Macro F1 Score: 0.4603\n",
      "\n",
      "--- Baseline (Majority Class: Everyone) ---\n",
      "Baseline Accuracy: 0.4704\n",
      "Baseline Macro F1 Score: 0.1600\n",
      "Improvement over baseline: Acc=+0.1150, F1=+0.3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate global model on test set\n",
    "global_preds, global_true = evaluate_model(global_model, test_loader_global)\n",
    "print(\"\\n=== Global Transformer Model Results (Tier Prediction) ===\")\n",
    "tier_names_list = ['Everyone (T0)', 'Teen (T1)', 'Mature (T2)', 'Adults Only (T3)']\n",
    "print(classification_report(global_true, global_preds, target_names=tier_names_list))\n",
    "\n",
    "global_accuracy = accuracy_score(global_true, global_preds)\n",
    "global_f1 = f1_score(global_true, global_preds, average='macro')  # Use macro for multi-class\n",
    "print(f\"Test Accuracy: {global_accuracy:.4f}\")\n",
    "print(f\"Test Macro F1 Score: {global_f1:.4f}\")\n",
    "\n",
    "# Baseline: predict majority class\n",
    "majority_class_global = Counter(global_true).most_common(1)[0][0]\n",
    "baseline_preds_global = [majority_class_global] * len(global_true)\n",
    "baseline_acc_global = accuracy_score(global_true, baseline_preds_global)\n",
    "baseline_f1_global = f1_score(global_true, baseline_preds_global, average='macro')\n",
    "\n",
    "print(f\"\\n--- Baseline (Majority Class: {tier_names[majority_class_global]}) ---\")\n",
    "print(f\"Baseline Accuracy: {baseline_acc_global:.4f}\")\n",
    "print(f\"Baseline Macro F1 Score: {baseline_f1_global:.4f}\")\n",
    "print(f\"Improvement over baseline: Acc={global_accuracy - baseline_acc_global:+.4f}, F1={global_f1 - baseline_f1_global:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a96eeb",
   "metadata": {},
   "source": [
    "### Model 2: Cluster-Aware Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe205328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster data distribution:\n",
      "  Cluster 0: 2920 samples (1881 mature, 1039 non-mature)\n",
      "  Cluster 1: 174 samples (135 mature, 39 non-mature)\n",
      "  Cluster 2: 2896 samples (3075 mature, -179 non-mature)\n",
      "  Cluster 3: 855 samples (1072 mature, -217 non-mature)\n",
      "  Cluster 4: 765 samples (428 mature, 337 non-mature)\n",
      "  Cluster 5: 1474 samples (1157 mature, 317 non-mature)\n",
      "  Cluster 6: 2084 samples (1539 mature, 545 non-mature)\n",
      "  Cluster 7: 31 samples (29 mature, 2 non-mature)\n",
      "  Cluster 8: 3161 samples (2984 mature, 177 non-mature)\n",
      "  Cluster 9: 353 samples (297 mature, 56 non-mature)\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from app_id to cluster\n",
    "appid_to_cluster = {}\n",
    "appid_to_game = {}\n",
    "\n",
    "for game, cluster_id in zip(all_games, clusters):\n",
    "    appid = str(game[\"app_id\"])\n",
    "    appid_to_cluster[appid] = cluster_id\n",
    "    appid_to_game[appid] = game\n",
    "\n",
    "# Prepare data organized by clusters\n",
    "def prepare_cluster_data(all_texts, all_labels, all_app_ids, appid_to_cluster):\n",
    "    \"\"\"Organize data by cluster.\"\"\"\n",
    "    cluster_data = {}\n",
    "    \n",
    "    for text, label, appid in zip(all_texts, all_labels, all_app_ids):\n",
    "        if appid not in appid_to_cluster:\n",
    "            continue\n",
    "        \n",
    "        cluster_id = appid_to_cluster[appid]\n",
    "        \n",
    "        if cluster_id not in cluster_data:\n",
    "            cluster_data[cluster_id] = {'texts': [], 'labels': [], 'app_ids': []}\n",
    "        \n",
    "        cluster_data[cluster_id]['texts'].append(text)\n",
    "        cluster_data[cluster_id]['labels'].append(label)\n",
    "        cluster_data[cluster_id]['app_ids'].append(appid)\n",
    "    \n",
    "    return cluster_data\n",
    "\n",
    "cluster_data = prepare_cluster_data(all_texts, all_labels, all_app_ids, appid_to_cluster)\n",
    "\n",
    "print(\"Cluster data distribution:\")\n",
    "for cluster_id in sorted(cluster_data.keys()):\n",
    "    n_samples = len(cluster_data[cluster_id]['texts'])\n",
    "    n_mature = sum(cluster_data[cluster_id]['labels'])\n",
    "    print(f\"  Cluster {cluster_id}: {n_samples} samples ({n_mature} mature, {n_samples-n_mature} non-mature)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e50333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training Cluster 0 Model (2920 samples)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.attention.q_lin.weight, embeddings.LayerNorm.bias, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.ffn.lin*.bias, transformer.layer.*.attention.k_lin.weight, transformer.layer.*.output_layer_norm.weight, transformer.layer.*.sa_layer_norm.weight, embeddings.position_embeddings.weight, embeddings.word_embeddings.weight, transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.attention.v_lin.bias\n",
      "/home/reczkok/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning:\n",
      "\n",
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "\n",
      "Epoch 1/15 - Training:   0%|                                                                    | 0/132 [00:00<?, ?it/s]/home/reczkok/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning:\n",
      "\n",
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "\n",
      "Epoch 1/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:21<00:00,  6.01it/s]\n",
      "Epoch 1/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:21<00:00,  6.01it/s]\n",
      "Epoch 1/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 14.87it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.3029, Val Loss=1.2818, Val Acc=0.5897, Val F1=0.1855 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:18<00:00,  7.05it/s]\n",
      "Epoch 2/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:18<00:00,  7.05it/s]\n",
      "Epoch 2/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 14.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=1.2632, Val Loss=1.2475, Val Acc=0.5855, Val F1=0.2703 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:18<00:00,  6.99it/s]\n",
      "Epoch 3/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:18<00:00,  6.99it/s]\n",
      "Epoch 3/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 15.32it/s]\n",
      "Epoch 3/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 15.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=1.1685, Val Loss=1.2564, Val Acc=0.5470, Val F1=0.2804 (no improvement 1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:20<00:00,  6.33it/s]\n",
      "Epoch 4/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:20<00:00,  6.33it/s]\n",
      "Epoch 4/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 15.28it/s]\n",
      "Epoch 4/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=1.0411, Val Loss=1.3652, Val Acc=0.5598, Val F1=0.3025 (no improvement 2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:18<00:00,  6.98it/s]\n",
      "Epoch 5/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:18<00:00,  6.98it/s]\n",
      "Epoch 5/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 14.71it/s]\n",
      "Epoch 5/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.8496, Val Loss=1.4328, Val Acc=0.5256, Val F1=0.3289 (no improvement 3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:20<00:00,  6.50it/s]\n",
      "Epoch 6/15 - Training: 100%|██████████████████████████████████████████████████████████| 132/132 [00:20<00:00,  6.50it/s]\n",
      "Epoch 6/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 14.31it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.6340, Val Loss=1.7022, Val Acc=0.5427, Val F1=0.2843 (no improvement 4/4)\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best validation loss: 1.2475\n",
      "Restored best model from validation\n",
      "\n",
      "==================================================\n",
      "Training Cluster 1 Model (174 samples)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Training Cluster 1 Model (174 samples)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.attention.q_lin.weight, embeddings.LayerNorm.bias, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.ffn.lin*.bias, transformer.layer.*.attention.k_lin.weight, transformer.layer.*.output_layer_norm.weight, transformer.layer.*.sa_layer_norm.weight, embeddings.position_embeddings.weight, embeddings.word_embeddings.weight, transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.attention.v_lin.bias\n",
      "/home/reczkok/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning:\n",
      "\n",
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "\n",
      "Epoch 1/15 - Training:   0%|                                                                      | 0/8 [00:00<?, ?it/s]/home/reczkok/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning:\n",
      "\n",
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "\n",
      "Epoch 1/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.56it/s]\n",
      "Epoch 1/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.56it/s]\n",
      "Epoch 1/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.27it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.3966, Val Loss=1.3196, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.64it/s]\n",
      "Epoch 2/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 2/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=1.2913, Val Loss=1.2811, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.70it/s]\n",
      "Epoch 3/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 3/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.61it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=1.3149, Val Loss=1.2718, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.74it/s]\n",
      "Epoch 4/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 4/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.20it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=1.2972, Val Loss=1.2687, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.70it/s]\n",
      "Epoch 5/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 5/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.67it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=1.3275, Val Loss=1.2674, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.69it/s]\n",
      "Epoch 6/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 6/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.34it/s]\n",
      "Epoch 6/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=1.2941, Val Loss=1.2763, Val Acc=0.5000, Val F1=0.1667 (no improvement 1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.71it/s]\n",
      "Epoch 7/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 7/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.46it/s]\n",
      "Epoch 7/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=1.2943, Val Loss=1.2750, Val Acc=0.5000, Val F1=0.1667 (no improvement 2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.71it/s]\n",
      "Epoch 8/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 8/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.63it/s]\n",
      "Epoch 8/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=1.2637, Val Loss=1.2715, Val Acc=0.5000, Val F1=0.1667 (no improvement 3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - Training: 100%|██████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.66it/s]\n",
      "Epoch 9/15 - Validation:   0%|                                                                    | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 9/15 - Validation: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=1.2447, Val Loss=1.2664, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - Training: 100%|█████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.74it/s]\n",
      "Epoch 10/15 - Validation:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 10/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.39it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=1.2401, Val Loss=1.2634, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - Training: 100%|█████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.67it/s]\n",
      "Epoch 11/15 - Validation:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 11/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.21it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.1930, Val Loss=1.2614, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - Training: 100%|█████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.46it/s]\n",
      "Epoch 12/15 - Validation:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 12/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.17it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.1486, Val Loss=1.2568, Val Acc=0.5000, Val F1=0.1667 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - Training: 100%|████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, -14.18it/s]\n",
      "Epoch 13/15 - Training: 100%|████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, -14.18it/s]\n",
      "Epoch 13/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.83it/s]\n",
      "Epoch 13/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.1799, Val Loss=1.2640, Val Acc=0.5000, Val F1=0.1750 (no improvement 1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - Training: 100%|█████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.43it/s]\n",
      "Epoch 14/15 - Validation:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 14/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.81it/s]\n",
      "Epoch 14/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=1.1029, Val Loss=1.2713, Val Acc=0.5714, Val F1=0.2556 (no improvement 2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - Training: 100%|█████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.52it/s]\n",
      "Epoch 15/15 - Validation:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 15/15 - Validation: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.75it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=1.0654, Val Loss=1.2734, Val Acc=0.5000, Val F1=0.1750 (no improvement 3/4)\n",
      "Restored best model from validation\n",
      "\n",
      "==================================================\n",
      "Training Cluster 2 Model (2896 samples)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Training Cluster 2 Model (2896 samples)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.attention.q_lin.weight, embeddings.LayerNorm.bias, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.ffn.lin*.bias, transformer.layer.*.attention.k_lin.weight, transformer.layer.*.output_layer_norm.weight, transformer.layer.*.sa_layer_norm.weight, embeddings.position_embeddings.weight, embeddings.word_embeddings.weight, transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.attention.v_lin.bias\n",
      "/home/reczkok/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning:\n",
      "\n",
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "\n",
      "Epoch 1/15 - Training:   0%|                                                                    | 0/131 [00:00<?, ?it/s]/home/reczkok/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning:\n",
      "\n",
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "\n",
      "Epoch 1/15 - Training: 100%|██████████████████████████████████████████████████████████| 131/131 [00:23<00:00,  5.54it/s]\n",
      "Epoch 1/15 - Training: 100%|██████████████████████████████████████████████████████████| 131/131 [00:23<00:00,  5.54it/s]\n",
      "Epoch 1/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.81it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.3490, Val Loss=1.2927, Val Acc=0.4569, Val F1=0.3583 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Training: 100%|██████████████████████████████████████████████████████████| 131/131 [00:20<00:00,  6.40it/s]\n",
      "Epoch 2/15 - Training: 100%|██████████████████████████████████████████████████████████| 131/131 [00:20<00:00,  6.40it/s]\n",
      "Epoch 2/15 - Validation: 100%|██████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.02it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=1.2585, Val Loss=1.2923, Val Acc=0.3966, Val F1=0.3126 ✓ (best)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Training:  60%|███████████████████████████████████▌                       | 79/131 [00:12<00:07,  6.52it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Train model with class weights for tier prediction\u001b[39;00m\n\u001b[32m     73\u001b[39m model = TransformerClassifier(num_classes=\u001b[32m4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m model, history = \u001b[43mtrain_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLUSTER_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcluster_class_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Move model to CPU and save immediately to free GPU memory\u001b[39;00m\n\u001b[32m     77\u001b[39m model = model.cpu()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mtrain_transformer\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, lr, class_weights)\u001b[39m\n\u001b[32m     28\u001b[39m model.train()\n\u001b[32m     29\u001b[39m train_losses = []\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m - Training\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mGameTextDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     13\u001b[39m text = \u001b[38;5;28mself\u001b[39m.texts[idx]\n\u001b[32m     14\u001b[39m label = \u001b[38;5;28mself\u001b[39m.labels[idx]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m encoding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m: encoding[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m].squeeze(\u001b[32m0\u001b[39m),\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m: encoding[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].squeeze(\u001b[32m0\u001b[39m),\n\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: torch.tensor(label, dtype=torch.long)\n\u001b[32m     28\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3073\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   3071\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   3072\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m3073\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3075\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3183\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   3161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_encode_plus(\n\u001b[32m   3162\u001b[39m         batch_text_or_text_pairs=batch_text_or_text_pairs,\n\u001b[32m   3163\u001b[39m         add_special_tokens=add_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3180\u001b[39m         **kwargs,\n\u001b[32m   3181\u001b[39m     )\n\u001b[32m   3182\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3186\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3258\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   3229\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3230\u001b[39m \u001b[33;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[32m   3231\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3246\u001b[39m \u001b[33;03m        method).\u001b[39;00m\n\u001b[32m   3247\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3249\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m   3250\u001b[39m     padding=padding,\n\u001b[32m   3251\u001b[39m     truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3255\u001b[39m     **kwargs,\n\u001b[32m   3256\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3261\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3277\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msplit_special_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3278\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3279\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils.py:800\u001b[39m, in \u001b[36mPreTrainedTokenizer._encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[32m    792\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    793\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    794\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    797\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    798\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m first_ids = \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m second_ids = get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prepare_for_model(\n\u001b[32m    804\u001b[39m     first_ids,\n\u001b[32m    805\u001b[39m     pair_ids=second_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m     verbose=verbose,\n\u001b[32m    821\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils.py:768\u001b[39m, in \u001b[36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    767\u001b[39m     tokens = \u001b[38;5;28mself\u001b[39m.tokenize(text, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_tokens_to_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[32m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    770\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_split_into_words:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils.py:729\u001b[39m, in \u001b[36mPreTrainedTokenizer.convert_tokens_to_ids\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m    727\u001b[39m ids = []\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m     ids.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_token_to_id_with_added_voc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils.py:738\u001b[39m, in \u001b[36mPreTrainedTokenizer._convert_token_to_id_with_added_voc\u001b[39m\u001b[34m(self, token)\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._added_tokens_encoder:\n\u001b[32m    737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._added_tokens_encoder[token]\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_token_to_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/models/distilbert/tokenization_distilbert.py:182\u001b[39m, in \u001b[36mDistilBertTokenizer._convert_token_to_id\u001b[39m\u001b[34m(self, token)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_token_to_id\u001b[39m(\u001b[38;5;28mself\u001b[39m, token):\n\u001b[32m    181\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Converts a token (str) in an id using the vocab.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vocab.get(token, \u001b[38;5;28mself\u001b[39m.vocab.get(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munk_token\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ppojda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1106\u001b[39m, in \u001b[36mSpecialTokensMixin.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__setattr__\u001b[39m(key, value)\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   1107\u001b[39m     key_without_id = key\n\u001b[32m   1108\u001b[39m     key_is_special_id = key.endswith(\u001b[33m\"\u001b[39m\u001b[33m_id\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key.endswith(\u001b[33m\"\u001b[39m\u001b[33m_ids\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train or load transformer models for each cluster\n",
    "MIN_SAMPLES_PER_CLUSTER = 50  # Minimum samples needed to train a cluster model\n",
    "CLUSTER_EPOCHS = 1  # Fewer epochs per cluster since we have less data\n",
    "\n",
    "cluster_models = {}\n",
    "cluster_histories = {}\n",
    "\n",
    "for cluster_id in sorted(cluster_data.keys()):\n",
    "    texts = cluster_data[cluster_id]['texts']\n",
    "    labels = cluster_data[cluster_id]['labels']\n",
    "    \n",
    "    # Skip clusters with too few samples\n",
    "    if len(texts) < MIN_SAMPLES_PER_CLUSTER:\n",
    "        print(f\"\\nCluster {cluster_id}: Skipping (only {len(texts)} samples)\")\n",
    "        continue\n",
    "    \n",
    "    # Check if we have multiple classes\n",
    "    unique_labels = set(labels)\n",
    "    if len(unique_labels) < 2:\n",
    "        print(f\"\\nCluster {cluster_id}: Skipping (only one class present)\")\n",
    "        continue\n",
    "    \n",
    "    model_path = f\"classificators/transformer_cluster_{cluster_id}_model_tier.pt\"\n",
    "    \n",
    "    # Split data (needed for both training and evaluation)\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    "        )\n",
    "            \n",
    "    except ValueError as e:\n",
    "        print(f\"Cluster {cluster_id}: Skipping due to stratification error\")\n",
    "        continue\n",
    "    \n",
    "    # Check if model already exists\n",
    "    if not FORCE_RETRAIN and os.path.exists(model_path):\n",
    "        print(f\"\\nCluster {cluster_id}: Loading existing model ({len(texts)} samples)\")\n",
    "        cluster_models[cluster_id] = {\n",
    "            'model_path': model_path,\n",
    "            'test_data': {'texts': X_test, 'labels': y_test}\n",
    "        }\n",
    "        cluster_histories[cluster_id] = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training Cluster {cluster_id} Model ({len(texts)} samples)\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Calculate class weights for this cluster\n",
    "    n_samples_cluster = len(y_train)\n",
    "    tier_counts_cluster = Counter(y_train)\n",
    "    cluster_class_weights = []\n",
    "    for tier in range(4):\n",
    "        if tier in tier_counts_cluster:\n",
    "            weight = (n_samples_cluster / (4 * tier_counts_cluster[tier])) ** 0.5\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        cluster_class_weights.append(weight)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = GameTextDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "    val_dataset = GameTextDataset(X_val, y_val, tokenizer, MAX_LENGTH)\n",
    "    test_dataset = GameTextDataset(X_test, y_test, tokenizer, MAX_LENGTH)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Train model with class weights for tier prediction\n",
    "    model = TransformerClassifier(num_classes=4)\n",
    "    model, history = train_transformer(model, train_loader, val_loader, epochs=CLUSTER_EPOCHS, lr=2e-5, class_weights=cluster_class_weights)\n",
    "    \n",
    "    # Move model to CPU and save immediately to free GPU memory\n",
    "    model = model.cpu()\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    cluster_models[cluster_id] = {\n",
    "        'model_path': model_path,\n",
    "        'test_data': {'texts': X_test, 'labels': y_test}\n",
    "    }\n",
    "    cluster_histories[cluster_id] = history\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    del model, train_dataset, val_dataset, test_dataset\n",
    "    del train_loader, val_loader, test_loader\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n\\nTotal cluster models available: {len(cluster_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a981434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cluster-Aware Transformer Model Results ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 37/37 [00:02<00:00, 12.61it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: Accuracy=0.5736, F1=0.2833, Samples=584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 16.72it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: Accuracy=0.5714, F1=0.2830, Samples=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 37/37 [00:03<00:00, 11.96it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 37/37 [00:03<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: Accuracy=0.4328, F1=0.3383, Samples=580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.74it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3: Accuracy=0.3977, F1=0.2939, Samples=171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 14.16it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4: Accuracy=0.6275, F1=0.1928, Samples=153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 19/19 [00:01<00:00, 11.96it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5: Accuracy=0.5220, F1=0.2838, Samples=295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00, 11.97it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6: Accuracy=0.6163, F1=0.3929, Samples=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 12.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 8: Accuracy=0.4771, F1=0.3567, Samples=633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: transformer.layer.*.ffn.lin*.weight, transformer.layer.*.attention.v_lin.weight, transformer.layer.*.attention.q_lin.bias, transformer.layer.*.attention.k_lin.bias, transformer.layer.*.attention.out_lin.weight, transformer.layer.*.attention.v_lin.bias, transformer.layer.*.attention.k_lin.weight, embeddings.LayerNorm.bias, embeddings.LayerNorm.weight, transformer.layer.*.sa_layer_norm.bias, transformer.layer.*.output_layer_norm.weight, embeddings.position_embeddings.weight, transformer.layer.*.attention.q_lin.weight, transformer.layer.*.ffn.lin*.bias, embeddings.word_embeddings.weight, transformer.layer.*.sa_layer_norm.weight, transformer.layer.*.output_layer_norm.bias, transformer.layer.*.attention.out_lin.bias\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 13.93it/s]\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 9: Accuracy=0.4930, F1=0.2242, Samples=71\n",
      "\n",
      "==================================================\n",
      "AGGREGATED CLUSTER-AWARE RESULTS (Tier Prediction)\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tier_names_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAGGREGATED CLUSTER-AWARE RESULTS (Tier Prediction)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(all_cluster_true, all_cluster_preds, target_names=\u001b[43mtier_names_list\u001b[49m))\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOverall Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOverall F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'tier_names_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate all cluster models and aggregate results\n",
    "print(\"\\n=== Cluster-Aware Transformer Model Results ===\\n\")\n",
    "\n",
    "# Calculate baseline (majority class) metrics\n",
    "baseline_preds_cluster = []\n",
    "all_cluster_preds = []\n",
    "all_cluster_true = []\n",
    "cluster_results = {}\n",
    "\n",
    "for cluster_id, data in cluster_models.items():\n",
    "    # Load model from disk to evaluate\n",
    "    model = TransformerClassifier(num_classes=4)\n",
    "    model.load_state_dict(torch.load(data['model_path'], map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create test loader\n",
    "    test_texts = data['test_data']['texts']\n",
    "    test_labels = data['test_data']['labels']\n",
    "    test_dataset = GameTextDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    preds, true_labels = evaluate_model(model, test_loader)\n",
    "    all_cluster_preds.extend(preds)\n",
    "    all_cluster_true.extend(true_labels)\n",
    "    \n",
    "    # Baseline: predict majority class for this cluster\n",
    "    majority_class = Counter(test_labels).most_common(1)[0][0]\n",
    "    baseline_preds_cluster.extend([majority_class] * len(true_labels))\n",
    "    \n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    f1 = f1_score(true_labels, preds, average='macro')  # Use macro for multi-class\n",
    "    \n",
    "    cluster_results[cluster_id] = {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'n_samples': len(true_labels)\n",
    "    }\n",
    "    \n",
    "    print(f\"Cluster {cluster_id}: Accuracy={acc:.4f}, F1={f1:.4f}, Samples={len(true_labels)}\")\n",
    "    \n",
    "    # Free memory\n",
    "    del model, test_dataset, test_loader\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Overall cluster-aware performance\n",
    "if all_cluster_preds:\n",
    "    cluster_accuracy = accuracy_score(all_cluster_true, all_cluster_preds)\n",
    "    cluster_f1 = f1_score(all_cluster_true, all_cluster_preds, average='macro')  # Use macro for multi-class\n",
    "    \n",
    "    # Baseline metrics\n",
    "    baseline_acc_cluster = accuracy_score(all_cluster_true, baseline_preds_cluster)\n",
    "    baseline_f1_cluster = f1_score(all_cluster_true, baseline_preds_cluster, average='macro')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"AGGREGATED CLUSTER-AWARE RESULTS (Tier Prediction)\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(all_cluster_true, all_cluster_preds, target_names=tier_names_list))\n",
    "    print(f\"Overall Accuracy: {cluster_accuracy:.4f}\")\n",
    "    print(f\"Overall F1 Score: {cluster_f1:.4f}\")\n",
    "    print(f\"\\n--- Baseline (Majority Class) ---\")\n",
    "    print(f\"Baseline Accuracy: {baseline_acc_cluster:.4f}\")\n",
    "    print(f\"Baseline F1 Score: {baseline_f1_cluster:.4f}\")\n",
    "    print(f\"Improvement over baseline: Acc={cluster_accuracy - baseline_acc_cluster:+.4f}, F1={cluster_f1 - baseline_f1_cluster:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cdbd47",
   "metadata": {},
   "source": [
    "### Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530d5631",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_acc_global' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create comparison summary with baseline\u001b[39;00m\n\u001b[32m      2\u001b[39m comparison_data = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mBaseline (Majority)\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGlobal Transformer\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCluster-Aware Transformer\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m: [\u001b[43mbaseline_acc_global\u001b[49m, global_accuracy, cluster_accuracy \u001b[38;5;28;01mif\u001b[39;00m all_cluster_preds \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mF1 Score (Macro)\u001b[39m\u001b[33m'\u001b[39m: [baseline_f1_global, global_f1, cluster_f1 \u001b[38;5;28;01mif\u001b[39;00m all_cluster_preds \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTest Samples\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28mlen\u001b[39m(global_true), \u001b[38;5;28mlen\u001b[39m(global_true), \u001b[38;5;28mlen\u001b[39m(all_cluster_true)]\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m comparison_df = pd.DataFrame(comparison_data)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'baseline_acc_global' is not defined"
     ]
    }
   ],
   "source": [
    "# Create comparison summary with baseline\n",
    "comparison_data = {\n",
    "    'Model': ['Baseline (Majority)', 'Global Transformer', 'Cluster-Aware Transformer'],\n",
    "    'Accuracy': [baseline_acc_global, global_accuracy, cluster_accuracy if all_cluster_preds else 0],\n",
    "    'F1 Score (Macro)': [baseline_f1_global, global_f1, cluster_f1 if all_cluster_preds else 0],\n",
    "    'Test Samples': [len(global_true), len(global_true), len(all_cluster_true)]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSFORMER MODEL COMPARISON (Tier Prediction 0-3)\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print()\n",
    "print(\"Note: Baseline predicts majority class (most common tier) in test set.\")\n",
    "print()\n",
    "\n",
    "# Determine winner\n",
    "if all_cluster_preds:\n",
    "    acc_diff = cluster_accuracy - global_accuracy\n",
    "    f1_diff = cluster_f1 - global_f1\n",
    "    \n",
    "    print(f\"Global vs Baseline: Acc={global_accuracy - 0.5:+.4f}, F1={global_f1 - 0.5:+.4f}\")\n",
    "    print(f\"Cluster vs Baseline: Acc={cluster_accuracy - 0.5:+.4f}, F1={cluster_f1 - 0.5:+.4f}\")\n",
    "    print(f\"\\nAccuracy Difference (Cluster - Global): {acc_diff:+.4f} ({'Cluster-Aware better' if acc_diff > 0 else 'Global better' if acc_diff < 0 else 'Tie'})\")\n",
    "    print(f\"F1 Score Difference (Cluster - Global): {f1_diff:+.4f} ({'Cluster-Aware better' if f1_diff > 0 else 'Global better' if f1_diff < 0 else 'Tie'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a7310e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m fig = make_subplots(rows=\u001b[32m1\u001b[39m, cols=\u001b[32m2\u001b[39m, subplot_titles=(\u001b[33m'\u001b[39m\u001b[33mAccuracy Comparison\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mF1 Score Comparison\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Accuracy bars\u001b[39;00m\n\u001b[32m      8\u001b[39m fig.add_trace(\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     go.Bar(name=\u001b[33m'\u001b[39m\u001b[33mGlobal\u001b[39m\u001b[33m'\u001b[39m, x=[\u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m], y=[\u001b[43mglobal_accuracy\u001b[49m], marker_color=\u001b[33m'\u001b[39m\u001b[33msteelblue\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     row=\u001b[32m1\u001b[39m, col=\u001b[32m1\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m fig.add_trace(\n\u001b[32m     13\u001b[39m     go.Bar(name=\u001b[33m'\u001b[39m\u001b[33mCluster-Aware\u001b[39m\u001b[33m'\u001b[39m, x=[\u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m], y=[cluster_accuracy \u001b[38;5;28;01mif\u001b[39;00m all_cluster_preds \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m], marker_color=\u001b[33m'\u001b[39m\u001b[33mcoral\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     14\u001b[39m     row=\u001b[32m1\u001b[39m, col=\u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# F1 Score bars  \u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'global_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualization: Bar chart comparison\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Accuracy Comparison', 'F1 Score Comparison'))\n",
    "\n",
    "# Accuracy bars\n",
    "fig.add_trace(\n",
    "    go.Bar(name='Global', x=['Accuracy'], y=[global_accuracy], marker_color='steelblue'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(name='Cluster-Aware', x=['Accuracy'], y=[cluster_accuracy if all_cluster_preds else 0], marker_color='coral'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# F1 Score bars  \n",
    "fig.add_trace(\n",
    "    go.Bar(name='Global', x=['F1 Score'], y=[global_f1], marker_color='steelblue', showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(name='Cluster-Aware', x=['F1 Score'], y=[cluster_f1 if all_cluster_preds else 0], marker_color='coral', showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Transformer Model Performance Comparison',\n",
    "    barmode='group',\n",
    "    height=400\n",
    ")\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc01fab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "steelblue"
         },
         "name": "Global Train",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
         ],
         "xaxis": "x",
         "y": [
          1.2811401079143334,
          1.1931215117420007,
          1.149925449045535,
          1.099147650810748,
          1.043459507225146,
          0.977896873497855,
          0.9060188014043402,
          0.8189158662591765
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "steelblue",
          "dash": "dash"
         },
         "name": "Global Val",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
         ],
         "xaxis": "x2",
         "y": [
          1.239127073739026,
          1.205237548093538,
          1.181213308830519,
          1.1735095655595935,
          1.204264847813426,
          1.2160874774327148,
          1.2779180874695648,
          1.310598242121774
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "coral"
         },
         "name": "Cluster Avg Train",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "xaxis": "x",
         "y": [
          1.3527764021170194,
          1.3117092898034293,
          1.273599325320799,
          1.2357636465401478,
          1.174071427557756,
          1.0743702115509812,
          0.9124433912100752,
          0.7695829448489891,
          0.6525206633457474,
          0.5071954014600061,
          0.5488036522247757,
          0.5111079651575822
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "coral",
          "dash": "dash"
         },
         "name": "Cluster Avg Val",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "xaxis": "x2",
         "y": [
          1.3107992716272425,
          1.2829288063088804,
          1.2787124657606241,
          1.2735959922366507,
          1.28808662259554,
          1.3155191328815352,
          1.371199647342267,
          1.4457765573547,
          1.5159518559773764,
          1.5163792939413163,
          1.4886481165885925,
          1.3579797744750977
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training Loss",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training Curves Comparison"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loss curves comparison\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Training Loss', 'Validation Loss'))\n",
    "\n",
    "# Global model training curve\n",
    "epochs_global = list(range(1, len(global_history['train_loss']) + 1))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs_global, y=global_history['train_loss'], name='Global Train', line=dict(color='steelblue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs_global, y=global_history['val_loss'], name='Global Val', line=dict(color='steelblue', dash='dash')),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Average cluster model training curves\n",
    "if cluster_histories:\n",
    "    avg_train_loss = []\n",
    "    avg_val_loss = []\n",
    "    max_epochs = max(len(h['train_loss']) for h in cluster_histories.values())\n",
    "    \n",
    "    for epoch_idx in range(max_epochs):\n",
    "        train_losses = [h['train_loss'][epoch_idx] for h in cluster_histories.values() if epoch_idx < len(h['train_loss'])]\n",
    "        val_losses = [h['val_loss'][epoch_idx] for h in cluster_histories.values() if epoch_idx < len(h['val_loss'])]\n",
    "        avg_train_loss.append(np.mean(train_losses))\n",
    "        avg_val_loss.append(np.mean(val_losses))\n",
    "    \n",
    "    epochs_cluster = list(range(1, len(avg_train_loss) + 1))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs_cluster, y=avg_train_loss, name='Cluster Avg Train', line=dict(color='coral')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs_cluster, y=avg_val_loss, name='Cluster Avg Val', line=dict(color='coral', dash='dash')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(title='Training Curves Comparison', height=400)\n",
    "fig.update_xaxes(title_text='Epoch')\n",
    "fig.update_yaxes(title_text='Loss')\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a075ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "steelblue"
         },
         "text": [
          "0.52",
          "0.80",
          "0.54",
          "0.35",
          "0.46",
          "0.49",
          "0.61",
          "0.70",
          "0.50",
          "0.41",
          "0.30",
          "0.50",
          "0.38",
          "0.41",
          "0.32",
          "0.36",
          "0.63",
          "0.54",
          "0.60",
          "0.64",
          "0.45",
          "0.41",
          "0.49"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Cluster 0",
          "Cluster 1",
          "Cluster 2",
          "Cluster 3",
          "Cluster 4",
          "Cluster 6",
          "Cluster 7",
          "Cluster 8",
          "Cluster 9",
          "Cluster 10",
          "Cluster 11",
          "Cluster 12",
          "Cluster 13",
          "Cluster 14",
          "Cluster 15",
          "Cluster 16",
          "Cluster 17",
          "Cluster 18",
          "Cluster 20",
          "Cluster 21",
          "Cluster 22",
          "Cluster 23",
          "Cluster 24"
         ],
         "xaxis": "x",
         "y": [
          0.5185185185185185,
          0.8028169014084507,
          0.538659793814433,
          0.35135135135135137,
          0.4631578947368421,
          0.4857142857142857,
          0.6129032258064516,
          0.6972477064220184,
          0.5,
          0.4066666666666667,
          0.29508196721311475,
          0.5,
          0.3829787234042553,
          0.4084507042253521,
          0.3235294117647059,
          0.3611111111111111,
          0.631578947368421,
          0.5423728813559322,
          0.5968379446640316,
          0.6391752577319587,
          0.45098039215686275,
          0.41150442477876104,
          0.4852941176470588
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "coral"
         },
         "text": [
          "0.17",
          "0.22",
          "0.35",
          "0.13",
          "0.36",
          "0.37",
          "0.19",
          "0.21",
          "0.17",
          "0.26",
          "0.18",
          "0.17",
          "0.22",
          "0.14",
          "0.27",
          "0.13",
          "0.19",
          "0.28",
          "0.49",
          "0.19",
          "0.16",
          "0.27",
          "0.37"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Cluster 0",
          "Cluster 1",
          "Cluster 2",
          "Cluster 3",
          "Cluster 4",
          "Cluster 6",
          "Cluster 7",
          "Cluster 8",
          "Cluster 9",
          "Cluster 10",
          "Cluster 11",
          "Cluster 12",
          "Cluster 13",
          "Cluster 14",
          "Cluster 15",
          "Cluster 16",
          "Cluster 17",
          "Cluster 18",
          "Cluster 20",
          "Cluster 21",
          "Cluster 22",
          "Cluster 23",
          "Cluster 24"
         ],
         "xaxis": "x2",
         "y": [
          0.17073170731707318,
          0.22440944881889763,
          0.3463617727872612,
          0.1326530612244898,
          0.3569313950544589,
          0.3691103875129285,
          0.19,
          0.20540540540540542,
          0.16666666666666666,
          0.26297912613702085,
          0.18053181225774784,
          0.16666666666666666,
          0.22244897959183674,
          0.145,
          0.2696741854636592,
          0.1326530612244898,
          0.1935483870967742,
          0.2753246753246753,
          0.49150595147346965,
          0.1949685534591195,
          0.1554054054054054,
          0.2701216797270981,
          0.37415720090066296
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Per-Cluster Accuracy",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Per-Cluster F1 Score",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "showarrow": false,
          "text": "Global: 0.54",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 0.5382262996941896,
          "yanchor": "bottom",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "Global: 0.42",
          "x": 1,
          "xanchor": "right",
          "xref": "x2 domain",
          "y": 0.421317717431472,
          "yanchor": "bottom",
          "yref": "y2"
         }
        ],
        "height": 700,
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 0.5382262996941896,
          "y1": 0.5382262996941896,
          "yref": "y"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x2 domain",
          "y0": 0.421317717431472,
          "y1": 0.421317717431472,
          "yref": "y2"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cluster-Specific Transformer Performance vs Global Model"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "range": [
          0,
          1.1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.375
         ],
         "range": [
          0,
          1.1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Per-cluster performance visualization\n",
    "if cluster_results:\n",
    "    cluster_ids = list(cluster_results.keys())\n",
    "    accuracies = [cluster_results[c]['accuracy'] for c in cluster_ids]\n",
    "    f1_scores = [cluster_results[c]['f1'] for c in cluster_ids]\n",
    "    n_samples = [cluster_results[c]['n_samples'] for c in cluster_ids]\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=('Per-Cluster Accuracy', 'Per-Cluster F1 Score'))\n",
    "    \n",
    "    # Accuracy per cluster\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=[f\"Cluster {c}\" for c in cluster_ids], \n",
    "            y=accuracies, \n",
    "            text=[f\"{a:.2f}\" for a in accuracies],\n",
    "            textposition='outside',\n",
    "            marker_color='steelblue'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add global accuracy line\n",
    "    fig.add_hline(y=global_accuracy, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=f\"Global: {global_accuracy:.2f}\", row=1, col=1)\n",
    "    \n",
    "    # F1 Score per cluster\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=[f\"Cluster {c}\" for c in cluster_ids], \n",
    "            y=f1_scores, \n",
    "            text=[f\"{f:.2f}\" for f in f1_scores],\n",
    "            textposition='outside',\n",
    "            marker_color='coral'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add global F1 line\n",
    "    fig.add_hline(y=global_f1, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=f\"Global: {global_f1:.2f}\", row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Cluster-Specific Transformer Performance vs Global Model',\n",
    "        height=700,\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_yaxes(range=[0, 1.1])\n",
    "    \n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3490bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SUMMARY - TIER PREDICTION (0-3)\n",
      "==================================================\n",
      "\n",
      "Dataset: 14713 games with tier labels\n",
      "  Tier 0 (Everyone): 6847 (46.5%)\n",
      "  Tier 1 (Teen): 4219 (28.7%)\n",
      "  Tier 2 (Mature): 2563 (17.4%)\n",
      "  Tier 3 (Adults Only): 1084 (7.4%)\n",
      "\n",
      "Clusters: 10 total, 9 with models\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'global_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Tier \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier_names[tier]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[32m100\u001b[39m*count/\u001b[38;5;28mlen\u001b[39m(all_labels)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClusters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_CLUSTERS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m total, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cluster_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGlobal Model:        Acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mglobal_accuracy\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_cluster_preds:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCluster-Aware Model: Acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'global_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"=\"*50)\n",
    "print(\"SUMMARY - TIER PREDICTION (0-3)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nDataset: {len(all_texts)} games with tier labels\")\n",
    "tier_distribution = Counter(all_labels)\n",
    "for tier in sorted(tier_distribution.keys()):\n",
    "    count = tier_distribution[tier]\n",
    "    print(f\"  Tier {tier} ({tier_names[tier]}): {count} ({100*count/len(all_labels):.1f}%)\")\n",
    "print(f\"\\nClusters: {NUM_CLUSTERS} total, {len(cluster_models)} with models\")\n",
    "\n",
    "print(f\"\\nGlobal Model:        Acc={global_accuracy:.4f}, F1={global_f1:.4f}\")\n",
    "\n",
    "if all_cluster_preds:\n",
    "    print(f\"Cluster-Aware Model: Acc={cluster_accuracy:.4f}, F1={cluster_f1:.4f}\")\n",
    "    \n",
    "    acc_diff = cluster_accuracy - global_accuracy\n",
    "    f1_diff = cluster_f1 - global_f1\n",
    "    \n",
    "    print(f\"\\nDifference: Acc={acc_diff:+.4f}, F1={f1_diff:+.4f}\")\n",
    "    winner = \"Cluster-Aware\" if (acc_diff + f1_diff) > 0 else \"Global\"\n",
    "    print(f\"Better model: {winner}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4862a1",
   "metadata": {},
   "source": [
    "### Evaluation on Top 100 Games by Review Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11dd7d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION ON TOP 100 GAMES BY REVIEW COUNT\n",
      "============================================================\n",
      "\n",
      "Evaluating on 100 top games\n",
      "\n",
      "\n",
      "Top 100 Tier Distribution:\n",
      "  Tier 0 (Everyone): 19 (19.0%)\n",
      "  Tier 1 (Teen): 23 (23.0%)\n",
      "  Tier 2 (Mature): 32 (32.0%)\n",
      "  Tier 3 (Adults Only): 26 (26.0%)\n",
      "\n",
      "Top 100 Source Distribution:\n",
      "  PEGI: 83 (83.0%)\n",
      "  ESRB: 17 (17.0%)\n",
      "\n",
      "=== Baseline (Majority Class: Mature) ===\n",
      "Correct: 32/100 (32.0%)\n",
      "\n",
      "=== Global Model on Top 100 ===\n",
      "Correct: 55/100 (55.0%)\n",
      "Improvement over baseline: +23 (+23.0%)\n",
      "\n",
      "============================================================\n",
      "MISCLASSIFIED GAMES (Global Model)\n",
      "============================================================\n",
      "• Team Fortress 2                               | T2(Mat)  | True: Mature       | Pred: Teen\n",
      "• Rust                                          | T3(Adu)  | True: Adults Only  | Pred: Teen\n",
      "• Baldur's Gate 3                               | T3(Adu)  | True: Adults Only  | Pred: Mature\n",
      "• Destiny 2                                     | T2(Mat)  | True: Mature       | Pred: Teen\n",
      "• Stardew Valley                                | T1(Tee)  | True: Teen         | Pred: Everyone\n",
      "• Cyberpunk 2077                                | T3(Adu)  | True: Adults Only  | Pred: Teen\n",
      "• Warframe                                      | T3(Adu)  | True: Adults Only  | Pred: Mature\n",
      "• ARK: Survival Evolved                         | T2(Mat)  | True: Mature       | Pred: Everyone\n",
      "• Dead by Daylight                              | T1(Tee)  | True: Teen         | Pred: Mature\n",
      "• The Witcher 3: Wild Hunt                      | T3(Adu)  | True: Adults Only  | Pred: Mature\n",
      "• Brawlhalla                                    | T0(Eve)  | True: Everyone     | Pred: Teen\n",
      "• Subnautica                                    | T1(Tee)  | True: Teen         | Pred: Everyone\n",
      "• Deep Rock Galactic                            | T2(Mat)  | True: Mature       | Pred: Everyone\n",
      "• New World: Aeternum                           | T2(Mat)  | True: Mature       | Pred: Teen\n",
      "• Path of Exile                                 | T3(Adu)  | True: Adults Only  | Pred: Mature\n",
      "• Hogwarts Legacy                               | T1(Tee)  | True: Teen         | Pred: Everyone\n",
      "• The Binding of Isaac: Rebirth                 | T2(Mat)  | True: Mature       | Pred: Teen\n",
      "• Raft                                          | T1(Tee)  | True: Teen         | Pred: Everyone\n",
      "• Doki Doki Literature Club!                    | T2(Mat)  | True: Mature       | Pred: Everyone\n",
      "• The Elder Scrolls V: Skyrim Special Edition   | T3(Adu)  | True: Adults Only  | Pred: Mature\n",
      "\n",
      "============================================================\n",
      "CORRECTLY CLASSIFIED TOP GAMES (Sample)\n",
      "============================================================\n",
      "✓ Tom Clancy's Rainbow Six® Siege X             | T2(Mat)  | Mature\n",
      "✓ HELLDIVERS™ 2                                 | T2(Mat)  | Mature\n",
      "✓ Terraria                                      | T1(Tee)  | Teen\n",
      "✓ Apex Legends™                                 | T1(Tee)  | Teen\n",
      "✓ ELDEN RING                                    | T2(Mat)  | Mature\n",
      "✓ Among Us                                      | T0(Eve)  | Everyone\n",
      "✓ War Thunder                                   | T1(Tee)  | Teen\n",
      "✓ Red Dead Redemption 2                         | T3(Adu)  | Adults Only\n",
      "✓ Call of Duty®                                 | T3(Adu)  | Adults Only\n",
      "✓ Rocket League®                                | T0(Eve)  | Everyone\n",
      "\n",
      "============================================================\n",
      "FULL RESULTS TABLE\n",
      "============================================================\n",
      "                                        title  review_count  tier  tier_label source true_label_str global_pred_str  global_correct\n",
      "            Tom Clancy's Rainbow Six® Siege X        734262     2      Mature   esrb         Mature          Mature            True\n",
      "                              Team Fortress 2        714797     2      Mature   pegi         Mature            Teen           False\n",
      "                                HELLDIVERS™ 2        593251     2      Mature   esrb         Mature          Mature            True\n",
      "                                     Terraria        567973     1        Teen   pegi           Teen            Teen            True\n",
      "                                         Rust        501936     3 Adults Only   pegi    Adults Only            Teen           False\n",
      "                                Apex Legends™        429334     1        Teen   esrb           Teen            Teen            True\n",
      "                              Baldur's Gate 3        420753     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                                   ELDEN RING        414562     2      Mature   pegi         Mature          Mature            True\n",
      "                                    Destiny 2        373269     2      Mature   pegi         Mature            Teen           False\n",
      "                               Stardew Valley        366195     1        Teen   pegi           Teen        Everyone           False\n",
      "                                     Among Us        364441     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                               Cyberpunk 2077        353121     3 Adults Only   pegi    Adults Only            Teen           False\n",
      "                                  War Thunder        281826     1        Teen   pegi           Teen            Teen            True\n",
      "                                     Warframe        277820     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                        Red Dead Redemption 2        265521     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                        ARK: Survival Evolved        250166     2      Mature   pegi         Mature        Everyone           False\n",
      "                             Dead by Daylight        237291     1        Teen   pegi           Teen          Mature           False\n",
      "                     The Witcher 3: Wild Hunt        227449     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                                Call of Duty®        226321     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                               Rocket League®        225747     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                Left 4 Dead 2        218200     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                                     PAYDAY 2        172371     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                                   The Forest        172139     2      Mature   pegi         Mature          Mature            True\n",
      "                                 No Man's Sky        170786     1        Teen   pegi           Teen            Teen            True\n",
      "                                         DayZ        170769     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                                   Brawlhalla        168397     0    Everyone   pegi       Everyone            Teen           False\n",
      "                                    Fall Guys        168123     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                   Subnautica        167480     1        Teen   pegi           Teen        Everyone           False\n",
      "                                     Portal 2        163603     1        Teen   pegi           Teen            Teen            True\n",
      "                           Deep Rock Galactic        163568     2      Mature   pegi         Mature        Everyone           False\n",
      "                                Hollow Knight        157655     0    Everyone   pegi       Everyone        Everyone            True\n",
      "            Halo: The Master Chief Collection        155261     2      Mature   pegi         Mature          Mature            True\n",
      "                                    Undertale        151595     1        Teen   pegi           Teen            Teen            True\n",
      "                               Risk of Rain 2        150121     1        Teen   pegi           Teen            Teen            True\n",
      "                          New World: Aeternum        142785     2      Mature   pegi         Mature            Teen           False\n",
      "                                Path of Exile        138207     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                                Halo Infinite        137297     2      Mature   pegi         Mature          Mature            True\n",
      "                                 Ready or Not        135081     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                                        Hades        134716     1        Teen   pegi           Teen            Teen            True\n",
      "                              Hogwarts Legacy        132832     1        Teen   pegi           Teen        Everyone           False\n",
      "                The Binding of Isaac: Rebirth        132491     2      Mature   pegi         Mature            Teen           False\n",
      "                       Euro Truck Simulator 2        132259     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                 Overwatch® 2        131067     1        Teen   esrb           Teen            Teen            True\n",
      "                                    Paladins®        127497     1        Teen   esrb           Teen            Teen            True\n",
      "                                         Raft        124242     1        Teen   pegi           Teen        Everyone           False\n",
      "                   Doki Doki Literature Club!        122674     2      Mature   esrb         Mature        Everyone           False\n",
      "                                Borderlands 2        121171     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                                7 Days to Die        121003     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "  The Elder Scrolls V: Skyrim Special Edition        119501     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                                 DOOM Eternal        117919     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                            Hearts of Iron IV        114357     0    Everyone   pegi       Everyone            Teen           False\n",
      "                        Monster Hunter: World        111438     2      Mature   pegi         Mature            Teen           False\n",
      "                            Battlefield™ 2042        105803     2      Mature   esrb         Mature          Mature            True\n",
      "                                     Lost Ark        104812     3 Adults Only   pegi    Adults Only            Teen           False\n",
      "                 Sid Meier’s Civilization® VI        103183     0    Everyone   esrb       Everyone            Teen           False\n",
      "                              DARK SOULS™ III        102984     2      Mature   pegi         Mature          Mature            True\n",
      "                                         Muck        100516     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                             Cities: Skylines         97156     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                  The Sims™ 4         96500     1        Teen   pegi           Teen        Everyone           False\n",
      "                                  Dying Light         92909     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                                     R.E.P.O.         92536     2      Mature   esrb         Mature        Everyone           False\n",
      "                 Mount & Blade II: Bannerlord         92318     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                          Hunt: Showdown 1896         90854     3 Adults Only   pegi    Adults Only     Adults Only            True\n",
      "                                      Balatro         90659     1        Teen   pegi           Teen        Everyone           False\n",
      "                                 Titanfall® 2         88505     2      Mature   esrb         Mature          Mature            True\n",
      "                     American Truck Simulator         86592     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                              Forza Horizon 5         83739     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                  Half-Life 2         83660     2      Mature   pegi         Mature     Adults Only           False\n",
      "                                    Starfield         82397     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                                         DOOM         81435     2      Mature   pegi         Mature     Adults Only           False\n",
      "             Warhammer 40,000: Space Marine 2         80402     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                                        Squad         80314     1        Teen   pegi           Teen          Mature           False\n",
      "Divinity: Original Sin 2 - Definitive Edition         79373     3 Adults Only   pegi    Adults Only          Mature           False\n",
      "                        Don't Starve Together         78993     1        Teen   pegi           Teen            Teen            True\n",
      "                STAR WARS Jedi: Fallen Order™         78711     1        Teen   esrb           Teen          Mature           False\n",
      "            Totally Accurate Battle Simulator         78207     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                       Portal         77041     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                  Life is Strange - Episode 1         74666     2      Mature   esrb         Mature          Mature            True\n",
      "                                        Stray         74491     2      Mature   pegi         Mature        Everyone           False\n",
      "                         Monster Hunter Wilds         73593     2      Mature   pegi         Mature          Mature            True\n",
      "                         Kerbal Space Program         73303     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                    Stellaris         72678     0    Everyone   pegi       Everyone            Teen           False\n",
      "                                  Inscryption         72307     2      Mature   pegi         Mature            Teen           False\n",
      "                    The Elder Scrolls® Online         72025     2      Mature   esrb         Mature          Mature            True\n",
      "                               Battlefield™ 6         70819     2      Mature   esrb         Mature          Mature            True\n",
      "                               Slay the Spire         68394     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                                       SMITE®         67979     1        Teen   esrb           Teen        Everyone           False\n",
      "                                     Teardown         67576     1        Teen   pegi           Teen            Teen            True\n",
      "                   Warhammer 40,000: Darktide         67295     2      Mature   esrb         Mature          Mature            True\n",
      "                  Clair Obscur: Expedition 33         66787     3 Adults Only   pegi    Adults Only            Teen           False\n",
      "                                   Far Cry® 5         66337     2      Mature   esrb         Mature     Adults Only           False\n",
      "                              Space Engineers         66261     1        Teen   pegi           Teen        Everyone           False\n",
      "                           Black Myth: Wukong         65923     2      Mature   pegi         Mature            Teen           False\n",
      "                                Slime Rancher         62564     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                        ELDEN RING NIGHTREIGN         62029     2      Mature   pegi         Mature            Teen           False\n",
      "                                      Cuphead         60045     0    Everyone   pegi       Everyone        Everyone            True\n",
      "                               Hell Let Loose         59168     2      Mature   pegi         Mature          Mature            True\n",
      "                                  Delta Force         58953     2      Mature   pegi         Mature          Mature            True\n",
      "                                Borderlands 3         58653     3 Adults Only   pegi    Adults Only            Teen           False\n",
      "                        Insurgency: Sandstorm         58122     3 Adults Only   pegi    Adults Only     Adults Only            True\n"
     ]
    }
   ],
   "source": [
    "# Evaluate both classifiers on top 100 games by review count\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION ON TOP 100 GAMES BY REVIEW COUNT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get top 100 games by review count that have unified labels\n",
    "top_100_games = sorted(\n",
    "    [g for g in all_games if str(g[\"app_id\"]) in unified_labels],\n",
    "    key=lambda g: g.get('review_count') or 0,\n",
    "    reverse=True\n",
    ")[:100]\n",
    "\n",
    "print(f\"\\nEvaluating on {len(top_100_games)} top games\\n\")\n",
    "\n",
    "# Prepare data for evaluation\n",
    "top_100_results = []\n",
    "\n",
    "for game in top_100_games:\n",
    "    appid = str(game[\"app_id\"])\n",
    "    label_data = unified_labels[appid]\n",
    "    tier = label_data['tier']\n",
    "    true_label = tier  # Use tier directly (0-3)\n",
    "    \n",
    "    about = game.get(\"about_this_game\") or \"\"\n",
    "    desc = game.get(\"description\") or \"\"\n",
    "    text = f\"{about} {desc}\".strip()\n",
    "    \n",
    "    if not text:\n",
    "        continue\n",
    "    \n",
    "    # Global model prediction\n",
    "    global_model.eval()\n",
    "    encoding = tokenizer(text, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "        output = global_model(input_ids, attention_mask)\n",
    "        global_pred = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    # Cluster-aware model prediction\n",
    "    # cluster_id = appid_to_cluster.get(appid)\n",
    "    # if cluster_id is not None and cluster_id in cluster_models:\n",
    "    #     # Load cluster model\n",
    "    #     cluster_model = TransformerClassifier(num_classes=4)\n",
    "    #     cluster_model.load_state_dict(torch.load(cluster_models[cluster_id]['model_path'], map_location=device))\n",
    "    #     cluster_model = cluster_model.to(device)\n",
    "    #     cluster_model.eval()\n",
    "        \n",
    "    #     with torch.no_grad():\n",
    "    #         output = cluster_model(input_ids, attention_mask)\n",
    "    #         cluster_pred = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "    #     del cluster_model\n",
    "    #     torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    # else:\n",
    "    #     cluster_pred = None\n",
    "    \n",
    "    top_100_results.append({\n",
    "        'title': game.get('title', 'Unknown'),\n",
    "        'app_id': appid,\n",
    "        'review_count': game.get('review_count') or 0,\n",
    "        'tier': tier,\n",
    "        'tier_label': label_data['tier_label'],\n",
    "        'source': label_data['source'],\n",
    "        'true_label': true_label,\n",
    "        'global_pred': global_pred,\n",
    "        # 'cluster_pred': cluster_pred,\n",
    "        # 'cluster_id': cluster_id\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(top_100_results)\n",
    "tier_names = {0: \"Everyone\", 1: \"Teen\", 2: \"Mature\", 3: \"Adults Only\"}\n",
    "results_df['true_label_str'] = results_df['true_label'].map(tier_names)\n",
    "results_df['global_pred_str'] = results_df['global_pred'].map(tier_names)\n",
    "# results_df['cluster_pred_str'] = results_df['cluster_pred'].map({**tier_names, None: 'N/A'})\n",
    "results_df['global_correct'] = results_df['true_label'] == results_df['global_pred']\n",
    "# results_df['cluster_correct'] = results_df.apply(\n",
    "#     lambda r: r['true_label'] == r['cluster_pred'] if r['cluster_pred'] is not None else None, axis=1\n",
    "# )\n",
    "# Summary statistics - show tier distribution\n",
    "n_games = len(results_df)\n",
    "tier_dist = results_df['true_label'].value_counts().sort_index()\n",
    "print(f\"\\nTop 100 Tier Distribution:\")\n",
    "for tier in sorted(tier_dist.index):\n",
    "    count = tier_dist[tier]\n",
    "    print(f\"  Tier {tier} ({tier_names[tier]}): {count} ({100*count/n_games:.1f}%)\")\n",
    "\n",
    "# Show source distribution in top 100\n",
    "source_counts_top100 = results_df['source'].value_counts()\n",
    "print(\"\\nTop 100 Source Distribution:\")\n",
    "for source, count in source_counts_top100.items():\n",
    "    print(f\"  {source.upper()}: {count} ({100*count/n_games:.1f}%)\")\n",
    "\n",
    "# Baseline: predict majority class\n",
    "majority_class_top100 = Counter(results_df['true_label']).most_common(1)[0][0]\n",
    "baseline_preds_top100 = [majority_class_top100] * n_games\n",
    "baseline_correct_top100 = sum(1 for true_label in results_df['true_label'] if true_label == majority_class_top100)\n",
    "print(f\"\\n=== Baseline (Majority Class: {tier_names[majority_class_top100]}) ===\")\n",
    "print(f\"Correct: {baseline_correct_top100}/{n_games} ({100*baseline_correct_top100/n_games:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Global Model on Top 100 ===\")\n",
    "global_correct = results_df['global_correct'].sum()\n",
    "print(f\"Correct: {global_correct}/{n_games} ({100*global_correct/n_games:.1f}%)\")\n",
    "print(f\"Improvement over baseline: {global_correct - baseline_correct_top100:+d} ({100*(global_correct - baseline_correct_top100)/n_games:+.1f}%)\")\n",
    "\n",
    "# cluster_evaluated = results_df['cluster_pred'].notna().sum()\n",
    "# cluster_correct = results_df['cluster_correct'].sum()\n",
    "# print(f\"\\n=== Cluster-Aware Model on Top 100 ===\")\n",
    "# print(f\"Games with cluster model: {cluster_evaluated}/{n_games}\")\n",
    "# if cluster_evaluated > 0:\n",
    "#     print(f\"Correct: {cluster_correct}/{cluster_evaluated} ({100*cluster_correct/cluster_evaluated:.1f}%)\")\n",
    "\n",
    "# Show misclassified games\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISCLASSIFIED GAMES (Global Model)\")\n",
    "print(\"=\"*60)\n",
    "misclassified = results_df[~results_df['global_correct']].head(20)\n",
    "for _, row in misclassified.iterrows():\n",
    "    tier_info = f\"T{row['tier']}({row['tier_label'][:3]})\"\n",
    "    print(f\"• {row['title'][:45]:<45} | {tier_info:<8} | True: {row['true_label_str']:<12} | Pred: {row['global_pred_str']}\")\n",
    "\n",
    "# Show sample of correct predictions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRECTLY CLASSIFIED TOP GAMES (Sample)\")\n",
    "print(\"=\"*60)\n",
    "correct = results_df[results_df['global_correct']].head(10)\n",
    "for _, row in correct.iterrows():\n",
    "    tier_info = f\"T{row['tier']}({row['tier_label'][:3]})\"\n",
    "    print(f\"✓ {row['title'][:45]:<45} | {tier_info:<8} | {row['true_label_str']}\")\n",
    "\n",
    "# Display full table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FULL RESULTS TABLE\")\n",
    "print(\"=\"*60)\n",
    "display_cols = ['title', 'review_count', 'tier', 'tier_label', 'source', 'true_label_str', 'global_pred_str', 'global_correct']\n",
    "print(results_df[display_cols].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steamscraper-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
